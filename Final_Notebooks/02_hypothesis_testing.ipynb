{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke Prediction Analysis - Statistical Hypothesis Testing\n",
    "\n",
    "## ðŸ“‹ Notebook Overview\n",
    "\n",
    "This notebook performs comprehensive statistical hypothesis testing for the stroke prediction dataset, building on the data quality assessment from the previous notebook. We'll establish statistical evidence for risk factors through rigorous testing methodology.\n",
    "\n",
    "### ðŸŽ¯ Objectives\n",
    "\n",
    "1. **Implement Missing Value Strategy**: Apply evidence-based imputation techniques\n",
    "2. **Define Research Hypotheses**: Establish clear, testable hypotheses for each risk factor\n",
    "3. **Test Statistical Assumptions**: Validate normality and other test prerequisites\n",
    "4. **Perform Hypothesis Tests**: Apply appropriate statistical tests with proper corrections\n",
    "5. **Quantify Effect Sizes**: Measure clinical significance beyond statistical significance\n",
    "6. **Generate Evidence Base**: Create foundation for feature engineering and modeling\n",
    "\n",
    "### ðŸ”¬ Scientific Methodology\n",
    "\n",
    "We follow rigorous medical research standards:\n",
    "- **Hypothesis Formation**: Clear null and alternative hypotheses\n",
    "- **Assumption Testing**: Validate statistical test prerequisites\n",
    "- **Appropriate Test Selection**: Choose tests based on data characteristics\n",
    "- **Multiple Testing Correction**: Control family-wise error rate\n",
    "- **Effect Size Analysis**: Clinical significance assessment\n",
    "- **Medical Domain Validation**: Interpret findings in clinical context\n",
    "\n",
    "### ðŸ“Š Expected Hypotheses\n",
    "\n",
    "Based on medical literature, we expect to test:\n",
    "\n",
    "1. **Hâ‚ (Age)**: Older age is associated with higher stroke risk\n",
    "2. **Hâ‚‚ (Hypertension)**: Hypertension increases stroke risk\n",
    "3. **Hâ‚ƒ (Heart Disease)**: Heart disease increases stroke risk\n",
    "4. **Hâ‚„ (Glucose)**: Higher glucose levels increase stroke risk\n",
    "5. **Hâ‚… (BMI)**: BMI is associated with stroke risk\n",
    "6. **Hâ‚† (Smoking)**: Smoking status affects stroke risk\n",
    "7. **Hâ‚‡ (Gender)**: Gender influences stroke risk patterns\n",
    "8. **Hâ‚ˆ (Social Factors)**: Marital status and work type affect stroke risk\n",
    "\n",
    "### ðŸ¥ Clinical Significance Standards\n",
    "\n",
    "- **Odds Ratio**: >1.5 for clinical relevance\n",
    "- **Effect Size**: Cohen's d >0.3 for practical significance\n",
    "- **Age Difference**: >5 years for clinical meaning\n",
    "- **Glucose Difference**: >20 mg/dL for clinical relevance\n",
    "- **BMI Difference**: >2 kg/mÂ² for clinical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Library Imports and Statistical Setup\n",
    "\n",
    "Comprehensive setup for advanced statistical hypothesis testing with medical domain expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "SciPy version: Available\n",
      "Statsmodels available: 0.14.4\n"
     ]
    }
   ],
   "source": [
    "# Core data processing libraries\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Statistical testing libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import (\n",
    "    chi2_contingency, fisher_exact, ttest_ind, mannwhitneyu,\n",
    "    shapiro, kstest, anderson, normaltest,\n",
    "    pearsonr, spearmanr, pointbiserialr,\n",
    "    levene, bartlett, f_oneway, kruskal\n",
    ")\n",
    "\n",
    "# Advanced statistical analysis\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.stats.weightstats import ttest_ind as ttest_ind_sm\n",
    "\n",
    "# Missing value imputation\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pl.Config.set_tbl_rows(20)\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"SciPy version: {stats.__version__ if hasattr(stats, '__version__') else 'Available'}\")\n",
    "print(f\"Statsmodels available: {sm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Data Loading and Missing Value Implementation\n",
    "\n",
    "Loading the dataset from the previous analysis and implementing the evidence-based missing value strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrokeHypothesisTestingPipeline:\n",
    "    \"\"\"\n",
    "    Comprehensive pipeline for statistical hypothesis testing in stroke prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, show_progress: bool = True):\n",
    "        self.show_progress = show_progress\n",
    "        self.df_original = None\n",
    "        self.df_cleaned = None\n",
    "        self.missing_strategy_log = []\n",
    "        self.test_results = {}\n",
    "        self.effect_sizes = {}\n",
    "        \n",
    "    def load_data_from_quality_analysis(self, file_path: str) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Load data with reference to quality analysis findings\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(\"=\"*80)\n",
    "            print(\"ðŸ“‚ LOADING DATA FROM QUALITY ANALYSIS\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        # Try multiple possible paths\n",
    "        possible_paths = [\n",
    "            file_path,\n",
    "            \"healthcare-dataset-stroke-data.csv\",\n",
    "            \"data/healthcare-dataset-stroke-data.csv\",\n",
    "            \"../data/healthcare-dataset-stroke-data.csv\"\n",
    "        ]\n",
    "        \n",
    "        df = None\n",
    "        loaded_path = None\n",
    "        \n",
    "        for path in possible_paths:\n",
    "            try:\n",
    "                if Path(path).exists():\n",
    "                    df = pl.read_csv(\n",
    "                        path,\n",
    "                        infer_schema_length=10000,\n",
    "                        try_parse_dates=True,\n",
    "                        null_values=['', 'NULL', 'null', 'NA', 'N/A', 'nan', 'NaN'],\n",
    "                        ignore_errors=False\n",
    "                    )\n",
    "                    loaded_path = path\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if df is None:\n",
    "            if self.show_progress:\n",
    "                print(\"âš ï¸  Could not find original dataset, creating sample for demonstration...\")\n",
    "            \n",
    "            # Create sample dataset for demonstration\n",
    "            np.random.seed(42)\n",
    "            sample_data = {\n",
    "                'id': range(1, 5111),\n",
    "                'gender': np.random.choice(['Male', 'Female', 'Other'], 5110, p=[0.45, 0.54, 0.01]),\n",
    "                'age': np.random.normal(43, 22, 5110).clip(18, 95),\n",
    "                'hypertension': np.random.choice([0, 1], 5110, p=[0.9, 0.1]),\n",
    "                'heart_disease': np.random.choice([0, 1], 5110, p=[0.95, 0.05]),\n",
    "                'ever_married': np.random.choice(['Yes', 'No'], 5110, p=[0.65, 0.35]),\n",
    "                'work_type': np.random.choice(['Private', 'Self-employed', 'Govt_job', 'children', 'Never_worked'], \n",
    "                                            5110, p=[0.57, 0.16, 0.13, 0.12, 0.02]),\n",
    "                'Residence_type': np.random.choice(['Urban', 'Rural'], 5110, p=[0.5, 0.5]),\n",
    "                'avg_glucose_level': np.random.normal(106, 45, 5110).clip(55, 300),\n",
    "                'bmi': np.random.normal(28.9, 7.5, 5110).clip(15, 50),\n",
    "                'smoking_status': np.random.choice(['never smoked', 'formerly smoked', 'smokes', 'Unknown'], \n",
    "                                                 5110, p=[0.37, 0.17, 0.15, 0.31]),\n",
    "                'stroke': np.random.choice([0, 1], 5110, p=[0.951, 0.049])\n",
    "            }\n",
    "            \n",
    "            df = pl.DataFrame(sample_data)\n",
    "            \n",
    "            # Add some missing values to BMI (realistic pattern)\n",
    "            bmi_array = df['bmi'].to_numpy()\n",
    "            missing_indices = np.random.choice(len(bmi_array), size=int(0.039 * len(bmi_array)), replace=False)\n",
    "            bmi_array[missing_indices] = None\n",
    "            df = df.with_columns(pl.Series('bmi', bmi_array))\n",
    "            \n",
    "            loaded_path = \"sample_dataset\"\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"âœ… Dataset loaded successfully!\")\n",
    "            print(f\"   Source: {loaded_path}\")\n",
    "            print(f\"   Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "            \n",
    "            # Quick quality overview\n",
    "            missing_count = sum([df[col].null_count() for col in df.columns])\n",
    "            print(f\"   Missing values: {missing_count:,}\")\n",
    "            \n",
    "            if 'stroke' in df.columns:\n",
    "                stroke_rate = df['stroke'].mean() * 100\n",
    "                print(f\"   Stroke prevalence: {stroke_rate:.1f}%\")\n",
    "        \n",
    "        self.df_original = df\n",
    "        return df\n",
    "    \n",
    "    def implement_missing_value_strategy(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Implement evidence-based missing value imputation strategy\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"ðŸ”§ IMPLEMENTING MISSING VALUE STRATEGY\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        df_cleaned = df.clone()\n",
    "        \n",
    "        # Analyze missing values first\n",
    "        missing_analysis = {}\n",
    "        for col in df.columns:\n",
    "            missing_count = df[col].null_count()\n",
    "            if missing_count > 0:\n",
    "                missing_pct = (missing_count / df.height) * 100\n",
    "                missing_analysis[col] = {\n",
    "                    'count': missing_count,\n",
    "                    'percentage': missing_pct\n",
    "                }\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nðŸ“Š Missing Values Overview:\")\n",
    "            if missing_analysis:\n",
    "                for col, info in missing_analysis.items():\n",
    "                    print(f\"   â€¢ {col}: {info['count']} ({info['percentage']:.1f}%)\")\n",
    "            else:\n",
    "                print(\"   âœ… No missing values found!\")\n",
    "        \n",
    "        # Strategy 1: BMI Imputation (if missing)\n",
    "        if 'bmi' in missing_analysis:\n",
    "            if self.show_progress:\n",
    "                print(f\"\\nðŸ”§ BMI Imputation Strategy:\")\n",
    "                print(\"   Method: KNN Imputation using age, gender, and health status\")\n",
    "            \n",
    "            # Convert to pandas for advanced imputation\n",
    "            df_pd = df_cleaned.to_pandas()\n",
    "            \n",
    "            # Prepare features for BMI imputation\n",
    "            impute_features = ['age']\n",
    "            if 'gender' in df_pd.columns:\n",
    "                # Encode gender for numeric imputation\n",
    "                le_gender = LabelEncoder()\n",
    "                df_pd['gender_encoded'] = le_gender.fit_transform(df_pd['gender'].astype(str))\n",
    "                impute_features.append('gender_encoded')\n",
    "            \n",
    "            if 'hypertension' in df_pd.columns:\n",
    "                impute_features.append('hypertension')\n",
    "            \n",
    "            if 'heart_disease' in df_pd.columns:\n",
    "                impute_features.append('heart_disease')\n",
    "            \n",
    "            # KNN Imputation for BMI\n",
    "            imputer = KNNImputer(n_neighbors=5)\n",
    "            features_for_imputation = df_pd[impute_features + ['bmi']].copy()\n",
    "            imputed_features = imputer.fit_transform(features_for_imputation)\n",
    "            \n",
    "            # Update BMI column\n",
    "            df_pd['bmi'] = imputed_features[:, -1]  # BMI is the last column\n",
    "            \n",
    "            # Convert back to Polars\n",
    "            df_cleaned = pl.from_pandas(df_pd.drop('gender_encoded', axis=1, errors='ignore'))\n",
    "            \n",
    "            self.missing_strategy_log.append({\n",
    "                'variable': 'bmi',\n",
    "                'method': 'KNN Imputation',\n",
    "                'features_used': impute_features,\n",
    "                'missing_before': missing_analysis['bmi']['count'],\n",
    "                'rationale': 'BMI can be predicted from demographic and health factors'\n",
    "            })\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"   âœ… BMI imputation completed using {len(impute_features)} features\")\n",
    "        \n",
    "        # Strategy 2: Smoking Status (if missing)\n",
    "        if 'smoking_status' in missing_analysis:\n",
    "            if self.show_progress:\n",
    "                print(f\"\\nðŸ”§ Smoking Status Strategy:\")\n",
    "                print(\"   Method: Create 'Unknown' category (clinically meaningful)\")\n",
    "            \n",
    "            df_cleaned = df_cleaned.with_columns([\n",
    "                pl.col('smoking_status').fill_null('Unknown')\n",
    "            ])\n",
    "            \n",
    "            self.missing_strategy_log.append({\n",
    "                'variable': 'smoking_status',\n",
    "                'method': 'Unknown Category',\n",
    "                'missing_before': missing_analysis['smoking_status']['count'],\n",
    "                'rationale': 'Missing smoking data is clinically informative'\n",
    "            })\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"   âœ… Smoking status: {missing_analysis['smoking_status']['count']} â†’ 'Unknown'\")\n",
    "        \n",
    "        # Strategy 3: Other variables (if any)\n",
    "        remaining_missing = {}\n",
    "        for col in df_cleaned.columns:\n",
    "            missing_count = df_cleaned[col].null_count()\n",
    "            if missing_count > 0:\n",
    "                remaining_missing[col] = missing_count\n",
    "        \n",
    "        if remaining_missing:\n",
    "            if self.show_progress:\n",
    "                print(f\"\\nðŸ”§ Handling Remaining Missing Values:\")\n",
    "            \n",
    "            for col, missing_count in remaining_missing.items():\n",
    "                if df_cleaned[col].dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64, \n",
    "                                           pl.Float32, pl.Float64]:\n",
    "                    # Median imputation for numerical\n",
    "                    median_val = df_cleaned[col].median()\n",
    "                    df_cleaned = df_cleaned.with_columns([\n",
    "                        pl.col(col).fill_null(median_val)\n",
    "                    ])\n",
    "                    method = f\"Median imputation ({median_val:.2f})\"\n",
    "                else:\n",
    "                    # Mode imputation for categorical\n",
    "                    mode_val = df_cleaned[col].mode().first()\n",
    "                    df_cleaned = df_cleaned.with_columns([\n",
    "                        pl.col(col).fill_null(mode_val)\n",
    "                    ])\n",
    "                    method = f\"Mode imputation ('{mode_val}')\"\n",
    "                \n",
    "                self.missing_strategy_log.append({\n",
    "                    'variable': col,\n",
    "                    'method': method,\n",
    "                    'missing_before': missing_count,\n",
    "                    'rationale': 'Simple imputation for minimal missing data'\n",
    "                })\n",
    "                \n",
    "                if self.show_progress:\n",
    "                    print(f\"   â€¢ {col}: {method}\")\n",
    "        \n",
    "        # Verify no missing values remain\n",
    "        final_missing = sum([df_cleaned[col].null_count() for col in df_cleaned.columns])\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nâœ… Missing Value Strategy Implementation Complete!\")\n",
    "            print(f\"   Missing values before: {sum([info['count'] for info in missing_analysis.values()])}\")\n",
    "            print(f\"   Missing values after: {final_missing}\")\n",
    "            print(f\"   Imputation methods used: {len(self.missing_strategy_log)}\")\n",
    "        \n",
    "        self.df_cleaned = df_cleaned\n",
    "        return df_cleaned\n",
    "    \n",
    "    def define_research_hypotheses(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Define comprehensive research hypotheses for stroke prediction\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"ðŸ”¬ RESEARCH HYPOTHESES DEFINITION\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        hypotheses = {\n",
    "            'H1_age': {\n",
    "                'variable': 'age',\n",
    "                'type': 'continuous',\n",
    "                'null_hypothesis': 'Age has no association with stroke occurrence',\n",
    "                'alternative_hypothesis': 'Older age is associated with higher stroke risk',\n",
    "                'direction': 'one_tailed',\n",
    "                'test_method': 'Mann-Whitney U (if not normal) or t-test',\n",
    "                'clinical_importance': 'Age is the strongest known stroke risk factor',\n",
    "                'expected_effect': 'Large positive association',\n",
    "                'clinical_threshold': '5+ years difference for clinical significance'\n",
    "            },\n",
    "            \n",
    "            'H2_hypertension': {\n",
    "                'variable': 'hypertension',\n",
    "                'type': 'categorical',\n",
    "                'null_hypothesis': 'Hypertension status is independent of stroke occurrence',\n",
    "                'alternative_hypothesis': 'Hypertension is associated with increased stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Chi-square test of independence',\n",
    "                'clinical_importance': 'Major modifiable cardiovascular risk factor',\n",
    "                'expected_effect': 'Moderate to strong positive association (OR > 2.0)',\n",
    "                'clinical_threshold': 'OR > 1.5 for clinical relevance'\n",
    "            },\n",
    "            \n",
    "            'H3_heart_disease': {\n",
    "                'variable': 'heart_disease',\n",
    "                'type': 'categorical',\n",
    "                'null_hypothesis': 'Heart disease status is independent of stroke occurrence',\n",
    "                'alternative_hypothesis': 'Heart disease is associated with increased stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Chi-square test of independence',\n",
    "                'clinical_importance': 'Cardiovascular comorbidity increases stroke risk',\n",
    "                'expected_effect': 'Strong positive association (OR > 3.0)',\n",
    "                'clinical_threshold': 'OR > 2.0 for strong clinical evidence'\n",
    "            },\n",
    "            \n",
    "            'H4_glucose': {\n",
    "                'variable': 'avg_glucose_level',\n",
    "                'type': 'continuous',\n",
    "                'null_hypothesis': 'Average glucose level has no association with stroke',\n",
    "                'alternative_hypothesis': 'Higher glucose levels are associated with increased stroke risk',\n",
    "                'direction': 'one_tailed',\n",
    "                'test_method': 'Mann-Whitney U (if not normal) or t-test',\n",
    "                'clinical_importance': 'Diabetes/glucose control affects stroke risk',\n",
    "                'expected_effect': 'Moderate positive association',\n",
    "                'clinical_threshold': '20+ mg/dL difference for clinical significance'\n",
    "            },\n",
    "            \n",
    "            'H5_bmi': {\n",
    "                'variable': 'bmi',\n",
    "                'type': 'continuous',\n",
    "                'null_hypothesis': 'BMI has no association with stroke occurrence',\n",
    "                'alternative_hypothesis': 'BMI is associated with stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Mann-Whitney U (if not normal) or t-test',\n",
    "                'clinical_importance': 'Obesity relationship with stroke is complex (may be U-shaped)',\n",
    "                'expected_effect': 'Weak to moderate association',\n",
    "                'clinical_threshold': '2+ kg/mÂ² difference for clinical significance'\n",
    "            },\n",
    "            \n",
    "            'H6_smoking': {\n",
    "                'variable': 'smoking_status',\n",
    "                'type': 'categorical',\n",
    "                'null_hypothesis': 'Smoking status is independent of stroke occurrence',\n",
    "                'alternative_hypothesis': 'Smoking status is associated with stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Chi-square test of independence',\n",
    "                'clinical_importance': 'Major modifiable lifestyle risk factor',\n",
    "                'expected_effect': 'Moderate positive association for current/former smokers',\n",
    "                'clinical_threshold': 'OR > 1.3 for clinical relevance'\n",
    "            },\n",
    "            \n",
    "            'H7_gender': {\n",
    "                'variable': 'gender',\n",
    "                'type': 'categorical',\n",
    "                'null_hypothesis': 'Gender has no association with stroke occurrence',\n",
    "                'alternative_hypothesis': 'Gender is associated with different stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Chi-square test of independence',\n",
    "                'clinical_importance': 'Gender differences in stroke epidemiology',\n",
    "                'expected_effect': 'Weak to moderate association',\n",
    "                'clinical_threshold': 'OR > 1.2 for clinical relevance'\n",
    "            },\n",
    "            \n",
    "            'H8_marital_status': {\n",
    "                'variable': 'ever_married',\n",
    "                'type': 'categorical',\n",
    "                'null_hypothesis': 'Marital status is independent of stroke occurrence',\n",
    "                'alternative_hypothesis': 'Marital status is associated with stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Chi-square test of independence',\n",
    "                'clinical_importance': 'Social determinants may influence health outcomes',\n",
    "                'expected_effect': 'Weak association (potential confounding by age)',\n",
    "                'clinical_threshold': 'OR > 1.2 for clinical relevance'\n",
    "            },\n",
    "            \n",
    "            'H9_work_type': {\n",
    "                'variable': 'work_type',\n",
    "                'type': 'categorical',\n",
    "                'null_hypothesis': 'Work type is independent of stroke occurrence',\n",
    "                'alternative_hypothesis': 'Work type is associated with stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Chi-square test of independence',\n",
    "                'clinical_importance': 'Occupational factors and socioeconomic status',\n",
    "                'expected_effect': 'Weak association',\n",
    "                'clinical_threshold': 'OR > 1.2 for clinical relevance'\n",
    "            },\n",
    "            \n",
    "            'H10_residence': {\n",
    "                'variable': 'Residence_type',\n",
    "                'type': 'categorical',\n",
    "                'null_hypothesis': 'Residence type is independent of stroke occurrence',\n",
    "                'alternative_hypothesis': 'Residence type is associated with stroke risk',\n",
    "                'direction': 'two_tailed',\n",
    "                'test_method': 'Chi-square test of independence',\n",
    "                'clinical_importance': 'Urban vs rural healthcare access and lifestyle',\n",
    "                'expected_effect': 'Weak association',\n",
    "                'clinical_threshold': 'OR > 1.2 for clinical relevance'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nðŸ“‹ Research Hypotheses Defined:\")\n",
    "            print(f\"   Total hypotheses: {len(hypotheses)}\")\n",
    "            print(f\"   Continuous variables: {len([h for h in hypotheses.values() if h['type'] == 'continuous'])}\")\n",
    "            print(f\"   Categorical variables: {len([h for h in hypotheses.values() if h['type'] == 'categorical'])}\")\n",
    "            \n",
    "            print(f\"\\nðŸŽ¯ Hypothesis Summary:\")\n",
    "            for h_id, details in list(hypotheses.items())[:5]:  # Show first 5\n",
    "                print(f\"   {h_id}: {details['variable']} - {details['expected_effect']}\")\n",
    "            if len(hypotheses) > 5:\n",
    "                print(f\"   ... and {len(hypotheses) - 5} more\")\n",
    "        \n",
    "        return hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Hypothesis Testing Pipeline initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the testing pipeline\n",
    "pipeline = StrokeHypothesisTestingPipeline(show_progress=True)\n",
    "print(\"ðŸ”§ Hypothesis Testing Pipeline initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‚ Data Loading and Cleaning Implementation\n",
    "\n",
    "Loading the dataset and implementing our evidence-based missing value strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting data loading and cleaning process...\n",
      "================================================================================\n",
      "ðŸ“‚ LOADING DATA FROM QUALITY ANALYSIS\n",
      "================================================================================\n",
      "âœ… Dataset loaded successfully!\n",
      "   Source: ../data/healthcare-dataset-stroke-data.csv\n",
      "   Shape: 5,110 rows Ã— 12 columns\n",
      "   Missing values: 201\n",
      "   Stroke prevalence: 4.9%\n",
      "\n",
      "================================================================================\n",
      "ðŸ”§ IMPLEMENTING MISSING VALUE STRATEGY\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Missing Values Overview:\n",
      "   â€¢ bmi: 201 (3.9%)\n",
      "\n",
      "ðŸ”§ BMI Imputation Strategy:\n",
      "   Method: KNN Imputation using age, gender, and health status\n",
      "   âœ… BMI imputation completed using 4 features\n",
      "\n",
      "âœ… Missing Value Strategy Implementation Complete!\n",
      "   Missing values before: 201\n",
      "   Missing values after: 0\n",
      "   Imputation methods used: 1\n",
      "\n",
      "================================================================================\n",
      "ðŸ”¬ RESEARCH HYPOTHESES DEFINITION\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ Research Hypotheses Defined:\n",
      "   Total hypotheses: 10\n",
      "   Continuous variables: 3\n",
      "   Categorical variables: 7\n",
      "\n",
      "ðŸŽ¯ Hypothesis Summary:\n",
      "   H1_age: age - Large positive association\n",
      "   H2_hypertension: hypertension - Moderate to strong positive association (OR > 2.0)\n",
      "   H3_heart_disease: heart_disease - Strong positive association (OR > 3.0)\n",
      "   H4_glucose: avg_glucose_level - Moderate positive association\n",
      "   H5_bmi: bmi - Weak to moderate association\n",
      "   ... and 5 more\n",
      "\n",
      "ðŸŽ‰ Data preparation completed!\n",
      "   Original shape: (5110, 12)\n",
      "   Cleaned shape: (5110, 12)\n",
      "   Research hypotheses: 10\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "print(\"ðŸš€ Starting data loading and cleaning process...\")\n",
    "\n",
    "# Load data (adjust path as needed)\n",
    "DATASET_PATH = \"healthcaredatasetstrokedata 1.csv\"\n",
    "df_original = pipeline.load_data_from_quality_analysis(DATASET_PATH)\n",
    "\n",
    "# Implement missing value strategy\n",
    "df_cleaned = pipeline.implement_missing_value_strategy(df_original)\n",
    "\n",
    "# Define research hypotheses\n",
    "hypotheses = pipeline.define_research_hypotheses()\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Data preparation completed!\")\n",
    "print(f\"   Original shape: {df_original.shape}\")\n",
    "print(f\"   Cleaned shape: {df_cleaned.shape}\")\n",
    "print(f\"   Research hypotheses: {len(hypotheses)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Statistical Assumptions Testing\n",
    "\n",
    "Testing normality and other statistical assumptions to guide appropriate test selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalityTester:\n",
    "    \"\"\"\n",
    "    Comprehensive normality testing for appropriate statistical test selection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pl.DataFrame, show_progress: bool = True):\n",
    "        self.df = df\n",
    "        self.show_progress = show_progress\n",
    "        self.normality_results = {}\n",
    "    \n",
    "    def comprehensive_normality_testing(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Perform comprehensive normality testing for all continuous variables\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(\"=\"*80)\n",
    "            print(\"ðŸ“Š COMPREHENSIVE NORMALITY TESTING\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        # Identify continuous variables\n",
    "        continuous_vars = []\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64, \n",
    "                                    pl.Float32, pl.Float64]:\n",
    "                # Check if it's actually continuous (not binary)\n",
    "                unique_count = self.df[col].n_unique()\n",
    "                if unique_count > 10:  # More than 10 unique values = continuous\n",
    "                    continuous_vars.append(col)\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nIdentified continuous variables: {continuous_vars}\")\n",
    "        \n",
    "        for var in continuous_vars:\n",
    "            if self.show_progress:\n",
    "                print(f\"\\n{'='*20} {var.upper()} {'='*20}\")\n",
    "            \n",
    "            # Extract data\n",
    "            data = self.df[var].drop_nulls().to_numpy()\n",
    "            n_samples = len(data)\n",
    "            \n",
    "            if n_samples < 3:\n",
    "                if self.show_progress:\n",
    "                    print(f\"âš ï¸  Insufficient data for normality testing (n={n_samples})\")\n",
    "                continue\n",
    "            \n",
    "            # Initialize results dictionary\n",
    "            var_results = {\n",
    "                'variable': var,\n",
    "                'n_samples': n_samples,\n",
    "                'mean': np.mean(data),\n",
    "                'std': np.std(data),\n",
    "                'skewness': stats.skew(data),\n",
    "                'kurtosis': stats.kurtosis(data),\n",
    "                'tests': {}\n",
    "            }\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"Sample size: {n_samples:,}\")\n",
    "                print(f\"Mean: {var_results['mean']:.3f}\")\n",
    "                print(f\"Std: {var_results['std']:.3f}\")\n",
    "                print(f\"Skewness: {var_results['skewness']:.3f}\")\n",
    "                print(f\"Kurtosis: {var_results['kurtosis']:.3f}\")\n",
    "            \n",
    "            # Test 1: Shapiro-Wilk Test (best for n < 5000)\n",
    "            if n_samples <= 5000:\n",
    "                try:\n",
    "                    shapiro_stat, shapiro_p = shapiro(data)\n",
    "                    var_results['tests']['shapiro_wilk'] = {\n",
    "                        'statistic': shapiro_stat,\n",
    "                        'p_value': shapiro_p,\n",
    "                        'interpretation': 'Normal' if shapiro_p > 0.05 else 'Non-normal'\n",
    "                    }\n",
    "                    \n",
    "                    if self.show_progress:\n",
    "                        print(f\"Shapiro-Wilk: W = {shapiro_stat:.4f}, p = {shapiro_p:.4f} \"\n",
    "                              f\"({'Normal' if shapiro_p > 0.05 else 'Non-normal'})\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    if self.show_progress:\n",
    "                        print(f\"Shapiro-Wilk: Failed ({str(e)})\")\n",
    "            else:\n",
    "                if self.show_progress:\n",
    "                    print(\"Shapiro-Wilk: Skipped (n > 5000)\")\n",
    "            \n",
    "            # Test 2: Kolmogorov-Smirnov Test\n",
    "            try:\n",
    "                ks_stat, ks_p = kstest(data, 'norm', args=(np.mean(data), np.std(data)))\n",
    "                var_results['tests']['kolmogorov_smirnov'] = {\n",
    "                    'statistic': ks_stat,\n",
    "                    'p_value': ks_p,\n",
    "                    'interpretation': 'Normal' if ks_p > 0.05 else 'Non-normal'\n",
    "                }\n",
    "                \n",
    "                if self.show_progress:\n",
    "                    print(f\"Kolmogorov-Smirnov: D = {ks_stat:.4f}, p = {ks_p:.4f} \"\n",
    "                          f\"({'Normal' if ks_p > 0.05 else 'Non-normal'})\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                if self.show_progress:\n",
    "                    print(f\"Kolmogorov-Smirnov: Failed ({str(e)})\")\n",
    "            \n",
    "            # Test 3: Anderson-Darling Test\n",
    "            try:\n",
    "                ad_result = anderson(data, dist='norm')\n",
    "                var_results['tests']['anderson_darling'] = {\n",
    "                    'statistic': ad_result.statistic,\n",
    "                    'critical_values': ad_result.critical_values,\n",
    "                    'significance_levels': ad_result.significance_level,\n",
    "                    'interpretation': 'Normal' if ad_result.statistic < ad_result.critical_values[2] else 'Non-normal'  # 5% level\n",
    "                }\n",
    "                \n",
    "                if self.show_progress:\n",
    "                    print(f\"Anderson-Darling: AÂ² = {ad_result.statistic:.4f}\")\n",
    "                    print(f\"Critical value (5%): {ad_result.critical_values[2]:.4f} \"\n",
    "                          f\"({'Normal' if ad_result.statistic < ad_result.critical_values[2] else 'Non-normal'})\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                if self.show_progress:\n",
    "                    print(f\"Anderson-Darling: Failed ({str(e)})\")\n",
    "            \n",
    "            # Test 4: D'Agostino's normality test (for larger samples)\n",
    "            if n_samples >= 20:\n",
    "                try:\n",
    "                    dagostino_stat, dagostino_p = normaltest(data)\n",
    "                    var_results['tests']['dagostino'] = {\n",
    "                        'statistic': dagostino_stat,\n",
    "                        'p_value': dagostino_p,\n",
    "                        'interpretation': 'Normal' if dagostino_p > 0.05 else 'Non-normal'\n",
    "                    }\n",
    "                    \n",
    "                    if self.show_progress:\n",
    "                        print(f\"D'Agostino: Ï‡Â² = {dagostino_stat:.4f}, p = {dagostino_p:.4f} \"\n",
    "                              f\"({'Normal' if dagostino_p > 0.05 else 'Non-normal'})\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    if self.show_progress:\n",
    "                        print(f\"D'Agostino: Failed ({str(e)})\")\n",
    "            \n",
    "            # Overall normality assessment\n",
    "            test_results = []\n",
    "            for test_name, test_result in var_results['tests'].items():\n",
    "                if 'interpretation' in test_result:\n",
    "                    test_results.append(test_result['interpretation'] == 'Normal')\n",
    "            \n",
    "            if len(test_results) > 0:\n",
    "                normal_count = sum(test_results)\n",
    "                total_tests = len(test_results)\n",
    "                normality_consensus = normal_count / total_tests\n",
    "                \n",
    "                if normality_consensus >= 0.75:\n",
    "                    overall_assessment = \"NORMAL\"\n",
    "                elif normality_consensus >= 0.5:\n",
    "                    overall_assessment = \"QUESTIONABLE\"\n",
    "                else:\n",
    "                    overall_assessment = \"NON-NORMAL\"\n",
    "            else:\n",
    "                overall_assessment = \"INDETERMINATE\"\n",
    "            \n",
    "            var_results['overall_assessment'] = overall_assessment\n",
    "            var_results['normality_consensus'] = normality_consensus if 'normality_consensus' in locals() else 0\n",
    "            \n",
    "            # Recommended test\n",
    "            if overall_assessment == \"NORMAL\":\n",
    "                recommended_test = \"Parametric (t-test, ANOVA)\"\n",
    "            else:\n",
    "                recommended_test = \"Non-parametric (Mann-Whitney U, Kruskal-Wallis)\"\n",
    "            \n",
    "            var_results['recommended_test'] = recommended_test\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"\\nðŸŽ¯ Overall Assessment: {overall_assessment}\")\n",
    "                print(f\"   Normality consensus: {var_results['normality_consensus']:.1%}\")\n",
    "                print(f\"   Recommended tests: {recommended_test}\")\n",
    "                \n",
    "                # Interpretation notes\n",
    "                if abs(var_results['skewness']) > 1:\n",
    "                    print(f\"   Note: High skewness ({var_results['skewness']:.2f}) suggests non-normality\")\n",
    "                if abs(var_results['kurtosis']) > 1:\n",
    "                    print(f\"   Note: High kurtosis ({var_results['kurtosis']:.2f}) suggests heavy tails\")\n",
    "            \n",
    "            self.normality_results[var] = var_results\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nðŸ“‹ NORMALITY TESTING SUMMARY:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(f\"{'Variable':<20} {'Assessment':<15} {'Recommended Test':<25}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            for var, results in self.normality_results.items():\n",
    "                print(f\"{var:<20} {results['overall_assessment']:<15} {results['recommended_test']:<25}\")\n",
    "        \n",
    "        return self.normality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“Š COMPREHENSIVE NORMALITY TESTING\n",
      "================================================================================\n",
      "\n",
      "Identified continuous variables: ['id', 'age', 'avg_glucose_level', 'bmi']\n",
      "\n",
      "==================== ID ====================\n",
      "Sample size: 5,110\n",
      "Mean: 36517.829\n",
      "Std: 21159.651\n",
      "Skewness: -0.020\n",
      "Kurtosis: -1.212\n",
      "Shapiro-Wilk: Skipped (n > 5000)\n",
      "Kolmogorov-Smirnov: D = 0.0635, p = 0.0000 (Non-normal)\n",
      "Anderson-Darling: AÂ² = 59.6234\n",
      "Critical value (5%): 0.7860 (Non-normal)\n",
      "D'Agostino: Ï‡Â² = 4888.4024, p = 0.0000 (Non-normal)\n",
      "\n",
      "ðŸŽ¯ Overall Assessment: NON-NORMAL\n",
      "   Normality consensus: 0.0%\n",
      "   Recommended tests: Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n",
      "   Note: High kurtosis (-1.21) suggests heavy tails\n",
      "\n",
      "==================== AGE ====================\n",
      "Sample size: 5,110\n",
      "Mean: 43.227\n",
      "Std: 22.610\n",
      "Skewness: -0.137\n",
      "Kurtosis: -0.991\n",
      "Shapiro-Wilk: Skipped (n > 5000)\n",
      "Kolmogorov-Smirnov: D = 0.0507, p = 0.0000 (Non-normal)\n",
      "Anderson-Darling: AÂ² = 33.8564\n",
      "Critical value (5%): 0.7860 (Non-normal)\n",
      "D'Agostino: Ï‡Â² = 1120.5286, p = 0.0000 (Non-normal)\n",
      "\n",
      "ðŸŽ¯ Overall Assessment: NON-NORMAL\n",
      "   Normality consensus: 0.0%\n",
      "   Recommended tests: Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n",
      "\n",
      "==================== AVG_GLUCOSE_LEVEL ====================\n",
      "Sample size: 5,110\n",
      "Mean: 106.148\n",
      "Std: 45.279\n",
      "Skewness: 1.572\n",
      "Kurtosis: 1.678\n",
      "Shapiro-Wilk: Skipped (n > 5000)\n",
      "Kolmogorov-Smirnov: D = 0.1828, p = 0.0000 (Non-normal)\n",
      "Anderson-Darling: AÂ² = 352.0863\n",
      "Critical value (5%): 0.7860 (Non-normal)\n",
      "D'Agostino: Ï‡Â² = 1328.9358, p = 0.0000 (Non-normal)\n",
      "\n",
      "ðŸŽ¯ Overall Assessment: NON-NORMAL\n",
      "   Normality consensus: 0.0%\n",
      "   Recommended tests: Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n",
      "   Note: High skewness (1.57) suggests non-normality\n",
      "   Note: High kurtosis (1.68) suggests heavy tails\n",
      "\n",
      "==================== BMI ====================\n",
      "Sample size: 5,110\n",
      "Mean: 28.957\n",
      "Std: 7.765\n",
      "Skewness: 1.030\n",
      "Kurtosis: 3.380\n",
      "Shapiro-Wilk: Skipped (n > 5000)\n",
      "Kolmogorov-Smirnov: D = 0.0548, p = 0.0000 (Non-normal)\n",
      "Anderson-Darling: AÂ² = 30.4170\n",
      "Critical value (5%): 0.7860 (Non-normal)\n",
      "D'Agostino: Ï‡Â² = 1042.5425, p = 0.0000 (Non-normal)\n",
      "\n",
      "ðŸŽ¯ Overall Assessment: NON-NORMAL\n",
      "   Normality consensus: 0.0%\n",
      "   Recommended tests: Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n",
      "   Note: High skewness (1.03) suggests non-normality\n",
      "   Note: High kurtosis (3.38) suggests heavy tails\n",
      "\n",
      "ðŸ“‹ NORMALITY TESTING SUMMARY:\n",
      "--------------------------------------------------\n",
      "Variable             Assessment      Recommended Test         \n",
      "--------------------------------------------------\n",
      "id                   NON-NORMAL      Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n",
      "age                  NON-NORMAL      Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n",
      "avg_glucose_level    NON-NORMAL      Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n",
      "bmi                  NON-NORMAL      Non-parametric (Mann-Whitney U, Kruskal-Wallis)\n"
     ]
    }
   ],
   "source": [
    "# Perform normality testing\n",
    "normality_tester = NormalityTester(df_cleaned, show_progress=True)\n",
    "normality_results = normality_tester.comprehensive_normality_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Categorical Variables Hypothesis Testing\n",
    "\n",
    "Comprehensive testing of categorical variables vs stroke outcome using appropriate statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalHypothesisTester:\n",
    "    \"\"\"\n",
    "    Comprehensive hypothesis testing for categorical variables\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pl.DataFrame, normality_results: Dict, show_progress: bool = True):\n",
    "        self.df = df\n",
    "        self.normality_results = normality_results\n",
    "        self.show_progress = show_progress\n",
    "        self.categorical_results = {}\n",
    "    \n",
    "    def test_categorical_associations(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Test associations between categorical variables and stroke outcome\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(\"=\"*80)\n",
    "            print(\"ðŸ”¬ CATEGORICAL VARIABLES HYPOTHESIS TESTING\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        # Define categorical variables to test\n",
    "        categorical_vars = ['gender', 'hypertension', 'heart_disease', 'ever_married', \n",
    "                           'work_type', 'Residence_type', 'smoking_status']\n",
    "        \n",
    "        # Filter to available variables\n",
    "        available_vars = [var for var in categorical_vars if var in self.df.columns]\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"Testing {len(available_vars)} categorical variables against stroke outcome\")\n",
    "            print(f\"Variables: {available_vars}\")\n",
    "        \n",
    "        for var in available_vars:\n",
    "            if self.show_progress:\n",
    "                print(f\"\\n{'='*20} {var.upper()} vs STROKE {'='*20}\")\n",
    "            \n",
    "            self._test_single_categorical_variable(var)\n",
    "        \n",
    "        # Summary\n",
    "        if self.show_progress:\n",
    "            self._print_categorical_summary()\n",
    "        \n",
    "        return self.categorical_results\n",
    "    \n",
    "    def _test_single_categorical_variable(self, var: str):\n",
    "        \"\"\"\n",
    "        Comprehensive testing for a single categorical variable\n",
    "        \"\"\"\n",
    "        # Create contingency table\n",
    "        try:\n",
    "            contingency_table = (self.df\n",
    "                               .group_by([var, 'stroke'])\n",
    "                               .agg(pl.count().alias('count'))\n",
    "                               .pivot(index=var, columns='stroke', values='count', aggregate_function='first')\n",
    "                               .fill_null(0)\n",
    "                               .to_pandas()\n",
    "                               .set_index(var))\n",
    "            \n",
    "            # Ensure we have both stroke classes\n",
    "            if 0 not in contingency_table.columns:\n",
    "                contingency_table[0] = 0\n",
    "            if 1 not in contingency_table.columns:\n",
    "                contingency_table[1] = 0\n",
    "            \n",
    "            contingency_table = contingency_table[[0, 1]]  # Ensure order: no stroke, stroke\n",
    "            \n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âŒ Error creating contingency table: {e}\")\n",
    "            return\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(\"Contingency Table:\")\n",
    "            print(contingency_table)\n",
    "        \n",
    "        # Initialize results\n",
    "        var_results = {\n",
    "            'variable': var,\n",
    "            'contingency_table': contingency_table.to_dict(),\n",
    "            'tests': {}\n",
    "        }\n",
    "        \n",
    "        # Check minimum expected frequencies\n",
    "        expected_freq = chi2_contingency(contingency_table)[3]\n",
    "        min_expected = expected_freq.min()\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nMinimum expected frequency: {min_expected:.2f}\")\n",
    "        \n",
    "        # Test 1: Chi-square test of independence\n",
    "        try:\n",
    "            chi2_stat, chi2_p, chi2_dof, expected = chi2_contingency(contingency_table)\n",
    "            \n",
    "            var_results['tests']['chi_square'] = {\n",
    "                'statistic': chi2_stat,\n",
    "                'p_value': chi2_p,\n",
    "                'degrees_of_freedom': chi2_dof,\n",
    "                'expected_frequencies': expected.tolist(),\n",
    "                'min_expected_frequency': min_expected,\n",
    "                'valid': min_expected >= 5,\n",
    "                'interpretation': 'Significant' if chi2_p < 0.05 else 'Not significant'\n",
    "            }\n",
    "            \n",
    "            if self.show_progress:\n",
    "                validity = \"âœ…\" if min_expected >= 5 else \"âš ï¸\"\n",
    "                print(f\"Chi-square test: {validity}\")\n",
    "                print(f\"   Ï‡Â² = {chi2_stat:.4f}\")\n",
    "                print(f\"   df = {chi2_dof}\")\n",
    "                print(f\"   p = {chi2_p:.4f}\")\n",
    "                print(f\"   Result: {var_results['tests']['chi_square']['interpretation']}\")\n",
    "                \n",
    "                if min_expected < 5:\n",
    "                    print(f\"   âš ï¸  Warning: Low expected frequencies (min = {min_expected:.2f})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âŒ Chi-square test failed: {e}\")\n",
    "        \n",
    "        # Test 2: Fisher's exact test (for 2x2 tables or small frequencies)\n",
    "        if contingency_table.shape == (2, 2) and min_expected < 5:\n",
    "            try:\n",
    "                odds_ratio, fisher_p = fisher_exact(contingency_table)\n",
    "                \n",
    "                var_results['tests']['fisher_exact'] = {\n",
    "                    'odds_ratio': odds_ratio,\n",
    "                    'p_value': fisher_p,\n",
    "                    'interpretation': 'Significant' if fisher_p < 0.05 else 'Not significant'\n",
    "                }\n",
    "                \n",
    "                if self.show_progress:\n",
    "                    print(f\"Fisher's exact test: âœ…\")\n",
    "                    print(f\"   Odds ratio = {odds_ratio:.4f}\")\n",
    "                    print(f\"   p = {fisher_p:.4f}\")\n",
    "                    print(f\"   Result: {var_results['tests']['fisher_exact']['interpretation']}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                if self.show_progress:\n",
    "                    print(f\"âŒ Fisher's exact test failed: {e}\")\n",
    "        \n",
    "        # Effect size calculations\n",
    "        self._calculate_categorical_effect_sizes(var, contingency_table, var_results)\n",
    "        \n",
    "        # Clinical interpretation\n",
    "        self._add_clinical_interpretation(var, var_results)\n",
    "        \n",
    "        self.categorical_results[var] = var_results\n",
    "    \n",
    "    def _calculate_categorical_effect_sizes(self, var: str, contingency_table: pd.DataFrame, var_results: Dict):\n",
    "        \"\"\"\n",
    "        Calculate effect sizes for categorical associations\n",
    "        \"\"\"\n",
    "        try:\n",
    "            n = contingency_table.sum().sum()\n",
    "            chi2_stat = var_results['tests']['chi_square']['statistic']\n",
    "            \n",
    "            # CramÃ©r's V\n",
    "            min_dim = min(contingency_table.shape) - 1\n",
    "            cramers_v = np.sqrt(chi2_stat / (n * min_dim))\n",
    "            \n",
    "            var_results['effect_sizes'] = {\n",
    "                'cramers_v': cramers_v\n",
    "            }\n",
    "            \n",
    "            # Odds ratio (for 2x2 tables)\n",
    "            if contingency_table.shape == (2, 2):\n",
    "                a, b = contingency_table.iloc[0, 0], contingency_table.iloc[0, 1]\n",
    "                c, d = contingency_table.iloc[1, 0], contingency_table.iloc[1, 1]\n",
    "                \n",
    "                if b > 0 and c > 0:  # Avoid division by zero\n",
    "                    odds_ratio = (a * d) / (b * c)\n",
    "                    \n",
    "                    # 95% confidence interval for odds ratio\n",
    "                    log_or = np.log(odds_ratio)\n",
    "                    se_log_or = np.sqrt(1/a + 1/b + 1/c + 1/d)\n",
    "                    ci_lower = np.exp(log_or - 1.96 * se_log_or)\n",
    "                    ci_upper = np.exp(log_or + 1.96 * se_log_or)\n",
    "                    \n",
    "                    var_results['effect_sizes']['odds_ratio'] = odds_ratio\n",
    "                    var_results['effect_sizes']['or_ci_lower'] = ci_lower\n",
    "                    var_results['effect_sizes']['or_ci_upper'] = ci_upper\n",
    "                    \n",
    "                    if self.show_progress:\n",
    "                        print(f\"\\nEffect Sizes:\")\n",
    "                        print(f\"   CramÃ©r's V = {cramers_v:.4f}\")\n",
    "                        print(f\"   Odds Ratio = {odds_ratio:.4f} (95% CI: {ci_lower:.4f}-{ci_upper:.4f})\")\n",
    "                else:\n",
    "                    if self.show_progress:\n",
    "                        print(f\"\\nEffect Sizes:\")\n",
    "                        print(f\"   CramÃ©r's V = {cramers_v:.4f}\")\n",
    "                        print(f\"   Odds Ratio = Cannot calculate (zero cells)\")\n",
    "            else:\n",
    "                if self.show_progress:\n",
    "                    print(f\"\\nEffect Sizes:\")\n",
    "                    print(f\"   CramÃ©r's V = {cramers_v:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âŒ Effect size calculation failed: {e}\")\n",
    "    \n",
    "    def _add_clinical_interpretation(self, var: str, var_results: Dict):\n",
    "        \"\"\"\n",
    "        Add clinical interpretation of results\n",
    "        \"\"\"\n",
    "        interpretation = {\n",
    "            'statistical_significance': 'Not significant',\n",
    "            'clinical_significance': 'No clinical significance',\n",
    "            'clinical_recommendation': 'No evidence for clinical relevance'\n",
    "        }\n",
    "        \n",
    "        # Check for statistical significance\n",
    "        if 'chi_square' in var_results['tests']:\n",
    "            p_value = var_results['tests']['chi_square']['p_value']\n",
    "            if p_value < 0.05:\n",
    "                interpretation['statistical_significance'] = 'Statistically significant'\n",
    "                \n",
    "                # Assess clinical significance\n",
    "                if 'odds_ratio' in var_results.get('effect_sizes', {}):\n",
    "                    or_value = var_results['effect_sizes']['odds_ratio']\n",
    "                    \n",
    "                    if or_value > 2.0:\n",
    "                        interpretation['clinical_significance'] = 'Strong clinical significance'\n",
    "                        interpretation['clinical_recommendation'] = f'Strong risk factor - OR = {or_value:.2f}'\n",
    "                    elif or_value > 1.5:\n",
    "                        interpretation['clinical_significance'] = 'Moderate clinical significance'\n",
    "                        interpretation['clinical_recommendation'] = f'Moderate risk factor - OR = {or_value:.2f}'\n",
    "                    elif or_value > 1.2:\n",
    "                        interpretation['clinical_significance'] = 'Weak clinical significance'\n",
    "                        interpretation['clinical_recommendation'] = f'Weak risk factor - OR = {or_value:.2f}'\n",
    "                    elif or_value < 0.8:\n",
    "                        interpretation['clinical_significance'] = 'Potential protective factor'\n",
    "                        interpretation['clinical_recommendation'] = f'Potential protective factor - OR = {or_value:.2f}'\n",
    "                \n",
    "                # CramÃ©r's V interpretation\n",
    "                if 'cramers_v' in var_results.get('effect_sizes', {}):\n",
    "                    cramers_v = var_results['effect_sizes']['cramers_v']\n",
    "                    if cramers_v > 0.5:\n",
    "                        interpretation['effect_size_interpretation'] = 'Large effect'\n",
    "                    elif cramers_v > 0.3:\n",
    "                        interpretation['effect_size_interpretation'] = 'Medium effect'\n",
    "                    elif cramers_v > 0.1:\n",
    "                        interpretation['effect_size_interpretation'] = 'Small effect'\n",
    "                    else:\n",
    "                        interpretation['effect_size_interpretation'] = 'Negligible effect'\n",
    "        \n",
    "        var_results['clinical_interpretation'] = interpretation\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nðŸ¥ Clinical Interpretation:\")\n",
    "            print(f\"   Statistical: {interpretation['statistical_significance']}\")\n",
    "            print(f\"   Clinical: {interpretation['clinical_significance']}\")\n",
    "            print(f\"   Recommendation: {interpretation['clinical_recommendation']}\")\n",
    "    \n",
    "    def _print_categorical_summary(self):\n",
    "        \"\"\"\n",
    "        Print summary of all categorical tests\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸ“‹ CATEGORICAL HYPOTHESIS TESTING SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        significant_vars = []\n",
    "        non_significant_vars = []\n",
    "        \n",
    "        for var, results in self.categorical_results.items():\n",
    "            if 'chi_square' in results['tests']:\n",
    "                p_value = results['tests']['chi_square']['p_value']\n",
    "                if p_value < 0.05:\n",
    "                    significant_vars.append((var, p_value, results.get('effect_sizes', {})))\n",
    "                else:\n",
    "                    non_significant_vars.append((var, p_value))\n",
    "        \n",
    "        # Sort significant variables by p-value\n",
    "        significant_vars.sort(key=lambda x: x[1])\n",
    "        \n",
    "        print(f\"\\nâœ… SIGNIFICANT ASSOCIATIONS (p < 0.05):\")\n",
    "        if significant_vars:\n",
    "            print(f\"{'Variable':<20} {'p-value':<10} {'Odds Ratio':<12} {'CramÃ©r\\'s V':<12} {'Clinical':<15}\")\n",
    "            print(\"-\" * 75)\n",
    "            \n",
    "            for var, p_val, effect_sizes in significant_vars:\n",
    "                or_str = f\"{effect_sizes.get('odds_ratio', 'N/A'):.3f}\" if isinstance(effect_sizes.get('odds_ratio'), (int, float)) else 'N/A'\n",
    "                cv_str = f\"{effect_sizes.get('cramers_v', 'N/A'):.3f}\" if isinstance(effect_sizes.get('cramers_v'), (int, float)) else 'N/A'\n",
    "                \n",
    "                # Clinical assessment\n",
    "                if isinstance(effect_sizes.get('odds_ratio'), (int, float)):\n",
    "                    or_val = effect_sizes['odds_ratio']\n",
    "                    if or_val > 2.0:\n",
    "                        clinical = \"Strong\"\n",
    "                    elif or_val > 1.5:\n",
    "                        clinical = \"Moderate\"\n",
    "                    else:\n",
    "                        clinical = \"Weak\"\n",
    "                else:\n",
    "                    clinical = \"Unknown\"\n",
    "                \n",
    "                print(f\"{var:<20} {p_val:<10.4f} {or_str:<12} {cv_str:<12} {clinical:<15}\")\n",
    "        else:\n",
    "            print(\"   No significant associations found.\")\n",
    "        \n",
    "        print(f\"\\nâŒ NON-SIGNIFICANT ASSOCIATIONS (p â‰¥ 0.05):\")\n",
    "        if non_significant_vars:\n",
    "            for var, p_val in non_significant_vars:\n",
    "                print(f\"   â€¢ {var}: p = {p_val:.4f}\")\n",
    "        else:\n",
    "            print(\"   All variables were significant.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”¬ CATEGORICAL VARIABLES HYPOTHESIS TESTING\n",
      "================================================================================\n",
      "Testing 7 categorical variables against stroke outcome\n",
      "Variables: ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
      "\n",
      "==================== GENDER vs STROKE ====================\n",
      "Contingency Table:\n",
      "        0  1\n",
      "gender      \n",
      "Male    0  0\n",
      "Female  0  0\n",
      "Other   0  0\n",
      "\n",
      "Minimum expected frequency: nan\n",
      "Chi-square test: âš ï¸\n",
      "   Ï‡Â² = nan\n",
      "   df = 2\n",
      "   p = nan\n",
      "   Result: Not significant\n",
      "\n",
      "Effect Sizes:\n",
      "   CramÃ©r's V = nan\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "==================== HYPERTENSION vs STROKE ====================\n",
      "Contingency Table:\n",
      "              0  1\n",
      "hypertension      \n",
      "1             0  0\n",
      "0             0  0\n",
      "\n",
      "Minimum expected frequency: nan\n",
      "Chi-square test: âš ï¸\n",
      "   Ï‡Â² = nan\n",
      "   df = 1\n",
      "   p = nan\n",
      "   Result: Not significant\n",
      "\n",
      "Effect Sizes:\n",
      "   CramÃ©r's V = nan\n",
      "   Odds Ratio = Cannot calculate (zero cells)\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "==================== HEART_DISEASE vs STROKE ====================\n",
      "Contingency Table:\n",
      "               0  1\n",
      "heart_disease      \n",
      "1              0  0\n",
      "0              0  0\n",
      "\n",
      "Minimum expected frequency: nan\n",
      "Chi-square test: âš ï¸\n",
      "   Ï‡Â² = nan\n",
      "   df = 1\n",
      "   p = nan\n",
      "   Result: Not significant\n",
      "\n",
      "Effect Sizes:\n",
      "   CramÃ©r's V = nan\n",
      "   Odds Ratio = Cannot calculate (zero cells)\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "==================== EVER_MARRIED vs STROKE ====================\n",
      "Contingency Table:\n",
      "              0  1\n",
      "ever_married      \n",
      "No            0  0\n",
      "Yes           0  0\n",
      "\n",
      "Minimum expected frequency: nan\n",
      "Chi-square test: âš ï¸\n",
      "   Ï‡Â² = nan\n",
      "   df = 1\n",
      "   p = nan\n",
      "   Result: Not significant\n",
      "\n",
      "Effect Sizes:\n",
      "   CramÃ©r's V = nan\n",
      "   Odds Ratio = Cannot calculate (zero cells)\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "==================== WORK_TYPE vs STROKE ====================\n",
      "Contingency Table:\n",
      "               0  1\n",
      "work_type          \n",
      "Self-employed  0  0\n",
      "children       0  0\n",
      "Govt_job       0  0\n",
      "Never_worked   0  0\n",
      "Private        0  0\n",
      "\n",
      "Minimum expected frequency: nan\n",
      "Chi-square test: âš ï¸\n",
      "   Ï‡Â² = nan\n",
      "   df = 4\n",
      "   p = nan\n",
      "   Result: Not significant\n",
      "\n",
      "Effect Sizes:\n",
      "   CramÃ©r's V = nan\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "==================== RESIDENCE_TYPE vs STROKE ====================\n",
      "Contingency Table:\n",
      "                0  1\n",
      "Residence_type      \n",
      "Rural           0  0\n",
      "Urban           0  0\n",
      "\n",
      "Minimum expected frequency: nan\n",
      "Chi-square test: âš ï¸\n",
      "   Ï‡Â² = nan\n",
      "   df = 1\n",
      "   p = nan\n",
      "   Result: Not significant\n",
      "\n",
      "Effect Sizes:\n",
      "   CramÃ©r's V = nan\n",
      "   Odds Ratio = Cannot calculate (zero cells)\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "==================== SMOKING_STATUS vs STROKE ====================\n",
      "Contingency Table:\n",
      "                 0  1\n",
      "smoking_status       \n",
      "formerly smoked  0  0\n",
      "never smoked     0  0\n",
      "Unknown          0  0\n",
      "smokes           0  0\n",
      "\n",
      "Minimum expected frequency: nan\n",
      "Chi-square test: âš ï¸\n",
      "   Ï‡Â² = nan\n",
      "   df = 3\n",
      "   p = nan\n",
      "   Result: Not significant\n",
      "\n",
      "Effect Sizes:\n",
      "   CramÃ©r's V = nan\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“‹ CATEGORICAL HYPOTHESIS TESTING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "âœ… SIGNIFICANT ASSOCIATIONS (p < 0.05):\n",
      "   No significant associations found.\n",
      "\n",
      "âŒ NON-SIGNIFICANT ASSOCIATIONS (p â‰¥ 0.05):\n",
      "   â€¢ gender: p = nan\n",
      "   â€¢ hypertension: p = nan\n",
      "   â€¢ heart_disease: p = nan\n",
      "   â€¢ ever_married: p = nan\n",
      "   â€¢ work_type: p = nan\n",
      "   â€¢ Residence_type: p = nan\n",
      "   â€¢ smoking_status: p = nan\n"
     ]
    }
   ],
   "source": [
    "# Perform categorical hypothesis testing\n",
    "categorical_tester = CategoricalHypothesisTester(df_cleaned, normality_results, show_progress=True)\n",
    "categorical_results = categorical_tester.test_categorical_associations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Continuous Variables Hypothesis Testing\n",
    "\n",
    "Comprehensive testing of continuous variables vs stroke outcome using appropriate parametric or non-parametric tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousHypothesisTester:\n",
    "    \"\"\"\n",
    "    Comprehensive hypothesis testing for continuous variables\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df: pl.DataFrame, normality_results: Dict, show_progress: bool = True):\n",
    "        self.df = df\n",
    "        self.normality_results = normality_results\n",
    "        self.show_progress = show_progress\n",
    "        self.continuous_results = {}\n",
    "    \n",
    "    def test_continuous_associations(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Test associations between continuous variables and stroke outcome\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(\"=\"*80)\n",
    "            print(\"ðŸ“Š CONTINUOUS VARIABLES HYPOTHESIS TESTING\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        # Get continuous variables from normality testing\n",
    "        continuous_vars = list(self.normality_results.keys())\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"Testing {len(continuous_vars)} continuous variables against stroke outcome\")\n",
    "            print(f\"Variables: {continuous_vars}\")\n",
    "        \n",
    "        for var in continuous_vars:\n",
    "            if self.show_progress:\n",
    "                print(f\"\\n{'='*20} {var.upper()} vs STROKE {'='*20}\")\n",
    "            \n",
    "            self._test_single_continuous_variable(var)\n",
    "        \n",
    "        # Summary\n",
    "        if self.show_progress:\n",
    "            self._print_continuous_summary()\n",
    "        \n",
    "        return self.continuous_results\n",
    "    \n",
    "    def _test_single_continuous_variable(self, var: str):\n",
    "        \"\"\"\n",
    "        Comprehensive testing for a single continuous variable\n",
    "        \"\"\"\n",
    "        # Extract data by stroke status\n",
    "        try:\n",
    "            no_stroke_data = self.df.filter(pl.col('stroke') == 0)[var].drop_nulls().to_numpy()\n",
    "            stroke_data = self.df.filter(pl.col('stroke') == 1)[var].drop_nulls().to_numpy()\n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âŒ Error extracting data: {e}\")\n",
    "            return\n",
    "        \n",
    "        if len(no_stroke_data) == 0 or len(stroke_data) == 0:\n",
    "            if self.show_progress:\n",
    "                print(f\"âŒ Insufficient data for testing\")\n",
    "            return\n",
    "        \n",
    "        # Initialize results\n",
    "        var_results = {\n",
    "            'variable': var,\n",
    "            'descriptive_stats': {\n",
    "                'no_stroke': {\n",
    "                    'n': len(no_stroke_data),\n",
    "                    'mean': np.mean(no_stroke_data),\n",
    "                    'median': np.median(no_stroke_data),\n",
    "                    'std': np.std(no_stroke_data, ddof=1),\n",
    "                    'min': np.min(no_stroke_data),\n",
    "                    'max': np.max(no_stroke_data)\n",
    "                },\n",
    "                'stroke': {\n",
    "                    'n': len(stroke_data),\n",
    "                    'mean': np.mean(stroke_data),\n",
    "                    'median': np.median(stroke_data),\n",
    "                    'std': np.std(stroke_data, ddof=1),\n",
    "                    'min': np.min(stroke_data),\n",
    "                    'max': np.max(stroke_data)\n",
    "                }\n",
    "            },\n",
    "            'tests': {}\n",
    "        }\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"Sample sizes: No stroke = {len(no_stroke_data):,}, Stroke = {len(stroke_data):,}\")\n",
    "            print(f\"No stroke:  Mean = {var_results['descriptive_stats']['no_stroke']['mean']:.3f}, \"\n",
    "                  f\"SD = {var_results['descriptive_stats']['no_stroke']['std']:.3f}\")\n",
    "            print(f\"Stroke:     Mean = {var_results['descriptive_stats']['stroke']['mean']:.3f}, \"\n",
    "                  f\"SD = {var_results['descriptive_stats']['stroke']['std']:.3f}\")\n",
    "            \n",
    "            mean_diff = var_results['descriptive_stats']['stroke']['mean'] - var_results['descriptive_stats']['no_stroke']['mean']\n",
    "            print(f\"Mean difference: {mean_diff:.3f}\")\n",
    "        \n",
    "        # Determine test strategy based on normality\n",
    "        normality_info = self.normality_results.get(var, {})\n",
    "        use_parametric = normality_info.get('overall_assessment') == 'NORMAL'\n",
    "        \n",
    "        if self.show_progress:\n",
    "            test_strategy = \"Parametric\" if use_parametric else \"Non-parametric\"\n",
    "            print(f\"\\nTest strategy: {test_strategy} (based on normality assessment)\")\n",
    "        \n",
    "        # Parametric tests\n",
    "        if use_parametric:\n",
    "            self._perform_parametric_tests(var, no_stroke_data, stroke_data, var_results)\n",
    "        \n",
    "        # Non-parametric tests (always perform for comparison)\n",
    "        self._perform_nonparametric_tests(var, no_stroke_data, stroke_data, var_results)\n",
    "        \n",
    "        # Effect sizes\n",
    "        self._calculate_continuous_effect_sizes(var, no_stroke_data, stroke_data, var_results)\n",
    "        \n",
    "        # Clinical interpretation\n",
    "        self._add_continuous_clinical_interpretation(var, var_results)\n",
    "        \n",
    "        self.continuous_results[var] = var_results\n",
    "    \n",
    "    def _perform_parametric_tests(self, var: str, no_stroke_data: np.ndarray, stroke_data: np.ndarray, var_results: Dict):\n",
    "        \"\"\"\n",
    "        Perform parametric tests (t-tests)\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(f\"\\nðŸ“Š Parametric Tests:\")\n",
    "        \n",
    "        # Test for equal variances (Levene's test)\n",
    "        try:\n",
    "            levene_stat, levene_p = levene(no_stroke_data, stroke_data)\n",
    "            equal_variances = levene_p > 0.05\n",
    "            \n",
    "            var_results['tests']['levene_test'] = {\n",
    "                'statistic': levene_stat,\n",
    "                'p_value': levene_p,\n",
    "                'equal_variances': equal_variances,\n",
    "                'interpretation': 'Equal variances' if equal_variances else 'Unequal variances'\n",
    "            }\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"   Levene's test: F = {levene_stat:.4f}, p = {levene_p:.4f} \"\n",
    "                      f\"({'Equal variances' if equal_variances else 'Unequal variances'})\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"   âŒ Levene's test failed: {e}\")\n",
    "            equal_variances = True  # Default assumption\n",
    "        \n",
    "        # Independent samples t-test\n",
    "        try:\n",
    "            t_stat, t_p = ttest_ind(stroke_data, no_stroke_data, equal_var=equal_variances)\n",
    "            \n",
    "            test_type = \"Student's t-test\" if equal_variances else \"Welch's t-test\"\n",
    "            \n",
    "            var_results['tests']['t_test'] = {\n",
    "                'test_type': test_type,\n",
    "                'statistic': t_stat,\n",
    "                'p_value': t_p,\n",
    "                'equal_var_assumed': equal_variances,\n",
    "                'interpretation': 'Significant' if t_p < 0.05 else 'Not significant'\n",
    "            }\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"   {test_type}: t = {t_stat:.4f}, p = {t_p:.4f}\")\n",
    "                print(f\"   Result: {var_results['tests']['t_test']['interpretation']}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"   âŒ t-test failed: {e}\")\n",
    "    \n",
    "    def _perform_nonparametric_tests(self, var: str, no_stroke_data: np.ndarray, stroke_data: np.ndarray, var_results: Dict):\n",
    "        \"\"\"\n",
    "        Perform non-parametric tests (Mann-Whitney U)\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(f\"\\nðŸ“Š Non-parametric Tests:\")\n",
    "        \n",
    "        # Mann-Whitney U test\n",
    "        try:\n",
    "            u_stat, u_p = mannwhitneyu(stroke_data, no_stroke_data, alternative='two-sided')\n",
    "            \n",
    "            var_results['tests']['mann_whitney'] = {\n",
    "                'statistic': u_stat,\n",
    "                'p_value': u_p,\n",
    "                'interpretation': 'Significant' if u_p < 0.05 else 'Not significant'\n",
    "            }\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"   Mann-Whitney U: U = {u_stat:.1f}, p = {u_p:.4f}\")\n",
    "                print(f\"   Result: {var_results['tests']['mann_whitney']['interpretation']}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"   âŒ Mann-Whitney U test failed: {e}\")\n",
    "    \n",
    "    def _calculate_continuous_effect_sizes(self, var: str, no_stroke_data: np.ndarray, stroke_data: np.ndarray, var_results: Dict):\n",
    "        \"\"\"\n",
    "        Calculate effect sizes for continuous variables\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Cohen's d\n",
    "            mean_diff = np.mean(stroke_data) - np.mean(no_stroke_data)\n",
    "            pooled_std = np.sqrt(((len(no_stroke_data) - 1) * np.var(no_stroke_data, ddof=1) + \n",
    "                                (len(stroke_data) - 1) * np.var(stroke_data, ddof=1)) / \n",
    "                               (len(no_stroke_data) + len(stroke_data) - 2))\n",
    "            \n",
    "            cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n",
    "            \n",
    "            # Glass's delta (using control group SD)\n",
    "            glass_delta = mean_diff / np.std(no_stroke_data, ddof=1) if np.std(no_stroke_data, ddof=1) > 0 else 0\n",
    "            \n",
    "            # Point-biserial correlation\n",
    "            all_data = np.concatenate([no_stroke_data, stroke_data])\n",
    "            group_labels = np.concatenate([np.zeros(len(no_stroke_data)), np.ones(len(stroke_data))])\n",
    "            \n",
    "            point_biserial_r, pb_p = pointbiserialr(group_labels, all_data)\n",
    "            \n",
    "            # Effect size for Mann-Whitney (r = Z / sqrt(N))\n",
    "            if 'mann_whitney' in var_results['tests']:\n",
    "                n1, n2 = len(stroke_data), len(no_stroke_data)\n",
    "                # Approximate z-score from U statistic\n",
    "                u_stat = var_results['tests']['mann_whitney']['statistic']\n",
    "                expected_u = n1 * n2 / 2\n",
    "                std_u = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12)\n",
    "                z_score = (u_stat - expected_u) / std_u if std_u > 0 else 0\n",
    "                effect_size_r = abs(z_score) / np.sqrt(n1 + n2)\n",
    "            else:\n",
    "                effect_size_r = 0\n",
    "            \n",
    "            var_results['effect_sizes'] = {\n",
    "                'cohens_d': cohens_d,\n",
    "                'glass_delta': glass_delta,\n",
    "                'point_biserial_r': point_biserial_r,\n",
    "                'point_biserial_p': pb_p,\n",
    "                'mann_whitney_r': effect_size_r,\n",
    "                'mean_difference': mean_diff,\n",
    "                'pooled_std': pooled_std\n",
    "            }\n",
    "            \n",
    "            if self.show_progress:\n",
    "                print(f\"\\nðŸ“ Effect Sizes:\")\n",
    "                print(f\"   Cohen's d = {cohens_d:.4f}\")\n",
    "                print(f\"   Point-biserial r = {point_biserial_r:.4f} (p = {pb_p:.4f})\")\n",
    "                print(f\"   Mean difference = {mean_diff:.3f}\")\n",
    "                print(f\"   Mann-Whitney r = {effect_size_r:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âŒ Effect size calculation failed: {e}\")\n",
    "    \n",
    "    def _add_continuous_clinical_interpretation(self, var: str, var_results: Dict):\n",
    "        \"\"\"\n",
    "        Add clinical interpretation for continuous variables\n",
    "        \"\"\"\n",
    "        interpretation = {\n",
    "            'statistical_significance': 'Not significant',\n",
    "            'clinical_significance': 'No clinical significance',\n",
    "            'effect_size_interpretation': 'Negligible effect',\n",
    "            'clinical_recommendation': 'No evidence for clinical relevance'\n",
    "        }\n",
    "        \n",
    "        # Check statistical significance (prioritize non-parametric for robustness)\n",
    "        p_value = None\n",
    "        if 'mann_whitney' in var_results['tests']:\n",
    "            p_value = var_results['tests']['mann_whitney']['p_value']\n",
    "        elif 't_test' in var_results['tests']:\n",
    "            p_value = var_results['tests']['t_test']['p_value']\n",
    "        \n",
    "        if p_value is not None and p_value < 0.05:\n",
    "            interpretation['statistical_significance'] = 'Statistically significant'\n",
    "            \n",
    "            # Effect size interpretation\n",
    "            if 'cohens_d' in var_results.get('effect_sizes', {}):\n",
    "                cohens_d = abs(var_results['effect_sizes']['cohens_d'])\n",
    "                \n",
    "                if cohens_d >= 0.8:\n",
    "                    interpretation['effect_size_interpretation'] = 'Large effect'\n",
    "                elif cohens_d >= 0.5:\n",
    "                    interpretation['effect_size_interpretation'] = 'Medium effect'\n",
    "                elif cohens_d >= 0.2:\n",
    "                    interpretation['effect_size_interpretation'] = 'Small effect'\n",
    "                else:\n",
    "                    interpretation['effect_size_interpretation'] = 'Negligible effect'\n",
    "            \n",
    "            # Clinical significance based on variable-specific thresholds\n",
    "            mean_diff = var_results.get('effect_sizes', {}).get('mean_difference', 0)\n",
    "            \n",
    "            if var.lower() == 'age':\n",
    "                if abs(mean_diff) >= 10:\n",
    "                    interpretation['clinical_significance'] = 'Strong clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Major age difference: {mean_diff:.1f} years'\n",
    "                elif abs(mean_diff) >= 5:\n",
    "                    interpretation['clinical_significance'] = 'Moderate clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Meaningful age difference: {mean_diff:.1f} years'\n",
    "                else:\n",
    "                    interpretation['clinical_significance'] = 'Weak clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Small age difference: {mean_diff:.1f} years'\n",
    "            \n",
    "            elif 'glucose' in var.lower():\n",
    "                if abs(mean_diff) >= 30:\n",
    "                    interpretation['clinical_significance'] = 'Strong clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Major glucose difference: {mean_diff:.1f} mg/dL'\n",
    "                elif abs(mean_diff) >= 20:\n",
    "                    interpretation['clinical_significance'] = 'Moderate clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Meaningful glucose difference: {mean_diff:.1f} mg/dL'\n",
    "                else:\n",
    "                    interpretation['clinical_significance'] = 'Weak clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Small glucose difference: {mean_diff:.1f} mg/dL'\n",
    "            \n",
    "            elif 'bmi' in var.lower():\n",
    "                if abs(mean_diff) >= 3:\n",
    "                    interpretation['clinical_significance'] = 'Moderate clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Meaningful BMI difference: {mean_diff:.1f} kg/mÂ²'\n",
    "                elif abs(mean_diff) >= 2:\n",
    "                    interpretation['clinical_significance'] = 'Weak clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Small BMI difference: {mean_diff:.1f} kg/mÂ²'\n",
    "                else:\n",
    "                    interpretation['clinical_significance'] = 'No clinical significance'\n",
    "                    interpretation['clinical_recommendation'] = f'Trivial BMI difference: {mean_diff:.1f} kg/mÂ²'\n",
    "            \n",
    "            else:\n",
    "                # Generic interpretation\n",
    "                if abs(mean_diff) > 0:\n",
    "                    interpretation['clinical_recommendation'] = f'Mean difference: {mean_diff:.3f}'\n",
    "        \n",
    "        var_results['clinical_interpretation'] = interpretation\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"\\nðŸ¥ Clinical Interpretation:\")\n",
    "            print(f\"   Statistical: {interpretation['statistical_significance']}\")\n",
    "            print(f\"   Effect size: {interpretation['effect_size_interpretation']}\")\n",
    "            print(f\"   Clinical: {interpretation['clinical_significance']}\")\n",
    "            print(f\"   Recommendation: {interpretation['clinical_recommendation']}\")\n",
    "    \n",
    "    def _print_continuous_summary(self):\n",
    "        \"\"\"\n",
    "        Print summary of all continuous tests\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸ“‹ CONTINUOUS HYPOTHESIS TESTING SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        significant_vars = []\n",
    "        non_significant_vars = []\n",
    "        \n",
    "        for var, results in self.continuous_results.items():\n",
    "            # Use Mann-Whitney p-value as primary (more robust)\n",
    "            p_value = None\n",
    "            if 'mann_whitney' in results['tests']:\n",
    "                p_value = results['tests']['mann_whitney']['p_value']\n",
    "            elif 't_test' in results['tests']:\n",
    "                p_value = results['tests']['t_test']['p_value']\n",
    "            \n",
    "            if p_value is not None:\n",
    "                if p_value < 0.05:\n",
    "                    effect_sizes = results.get('effect_sizes', {})\n",
    "                    significant_vars.append((var, p_value, effect_sizes))\n",
    "                else:\n",
    "                    non_significant_vars.append((var, p_value))\n",
    "        \n",
    "        # Sort significant variables by p-value\n",
    "        significant_vars.sort(key=lambda x: x[1])\n",
    "        \n",
    "        print(f\"\\nâœ… SIGNIFICANT ASSOCIATIONS (p < 0.05):\")\n",
    "        if significant_vars:\n",
    "            print(f\"{'Variable':<20} {'p-value':<10} {'Cohen\\'s d':<12} {'Mean Diff':<12} {'Clinical':<15}\")\n",
    "            print(\"-\" * 75)\n",
    "            \n",
    "            for var, p_val, effect_sizes in significant_vars:\n",
    "                cohens_d = effect_sizes.get('cohens_d', 0)\n",
    "                mean_diff = effect_sizes.get('mean_difference', 0)\n",
    "                \n",
    "                # Clinical assessment\n",
    "                if var.lower() == 'age' and abs(mean_diff) >= 5:\n",
    "                    clinical = \"Strong\"\n",
    "                elif 'glucose' in var.lower() and abs(mean_diff) >= 20:\n",
    "                    clinical = \"Strong\"\n",
    "                elif 'bmi' in var.lower() and abs(mean_diff) >= 2:\n",
    "                    clinical = \"Moderate\"\n",
    "                elif abs(cohens_d) >= 0.5:\n",
    "                    clinical = \"Moderate\"\n",
    "                elif abs(cohens_d) >= 0.2:\n",
    "                    clinical = \"Weak\"\n",
    "                else:\n",
    "                    clinical = \"Minimal\"\n",
    "                \n",
    "                print(f\"{var:<20} {p_val:<10.4f} {cohens_d:<12.3f} {mean_diff:<12.3f} {clinical:<15}\")\n",
    "        else:\n",
    "            print(\"   No significant associations found.\")\n",
    "        \n",
    "        print(f\"\\nâŒ NON-SIGNIFICANT ASSOCIATIONS (p â‰¥ 0.05):\")\n",
    "        if non_significant_vars:\n",
    "            for var, p_val in non_significant_vars:\n",
    "                print(f\"   â€¢ {var}: p = {p_val:.4f}\")\n",
    "        else:\n",
    "            print(\"   All variables were significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“Š CONTINUOUS VARIABLES HYPOTHESIS TESTING\n",
      "================================================================================\n",
      "Testing 4 continuous variables against stroke outcome\n",
      "Variables: ['id', 'age', 'avg_glucose_level', 'bmi']\n",
      "\n",
      "==================== ID vs STROKE ====================\n",
      "Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "No stroke:  Mean = 36487.236, SD = 21120.133\n",
      "Stroke:     Mean = 37115.068, SD = 21993.345\n",
      "Mean difference: 627.832\n",
      "\n",
      "Test strategy: Non-parametric (based on normality assessment)\n",
      "\n",
      "ðŸ“Š Non-parametric Tests:\n",
      "   Mann-Whitney U: U = 615742.0, p = 0.6423\n",
      "   Result: Not significant\n",
      "\n",
      "ðŸ“ Effect Sizes:\n",
      "   Cohen's d = 0.0297\n",
      "   Point-biserial r = 0.0064 (p = 0.6480)\n",
      "   Mean difference = 627.832\n",
      "   Mann-Whitney r = 0.0065\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Not significant\n",
      "   Effect size: Negligible effect\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: No evidence for clinical relevance\n",
      "\n",
      "==================== AGE vs STROKE ====================\n",
      "Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "No stroke:  Mean = 41.972, SD = 22.292\n",
      "Stroke:     Mean = 67.728, SD = 12.727\n",
      "Mean difference: 25.757\n",
      "\n",
      "Test strategy: Non-parametric (based on normality assessment)\n",
      "\n",
      "ðŸ“Š Non-parametric Tests:\n",
      "   Mann-Whitney U: U = 1010125.5, p = 0.0000\n",
      "   Result: Significant\n",
      "\n",
      "ðŸ“ Effect Sizes:\n",
      "   Cohen's d = 1.1748\n",
      "   Point-biserial r = 0.2453 (p = 0.0000)\n",
      "   Mean difference = 25.757\n",
      "   Mann-Whitney r = 0.2495\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Statistically significant\n",
      "   Effect size: Large effect\n",
      "   Clinical: Strong clinical significance\n",
      "   Recommendation: Major age difference: 25.8 years\n",
      "\n",
      "==================== AVG_GLUCOSE_LEVEL vs STROKE ====================\n",
      "Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "No stroke:  Mean = 104.796, SD = 43.846\n",
      "Stroke:     Mean = 132.545, SD = 61.921\n",
      "Mean difference: 27.749\n",
      "\n",
      "Test strategy: Non-parametric (based on normality assessment)\n",
      "\n",
      "ðŸ“Š Non-parametric Tests:\n",
      "   Mann-Whitney U: U = 739150.0, p = 0.0000\n",
      "   Result: Significant\n",
      "\n",
      "ðŸ“ Effect Sizes:\n",
      "   Cohen's d = 0.6181\n",
      "   Point-biserial r = 0.1319 (p = 0.0000)\n",
      "   Mean difference = 27.749\n",
      "   Mann-Whitney r = 0.0825\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Statistically significant\n",
      "   Effect size: Medium effect\n",
      "   Clinical: Moderate clinical significance\n",
      "   Recommendation: Meaningful glucose difference: 27.7 mg/dL\n",
      "\n",
      "==================== BMI vs STROKE ====================\n",
      "Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "No stroke:  Mean = 28.877, SD = 7.838\n",
      "Stroke:     Mean = 30.510, SD = 5.998\n",
      "Mean difference: 1.633\n",
      "\n",
      "Test strategy: Non-parametric (based on normality assessment)\n",
      "\n",
      "ðŸ“Š Non-parametric Tests:\n",
      "   Mann-Whitney U: U = 705754.0, p = 0.0000\n",
      "   Result: Significant\n",
      "\n",
      "ðŸ“ Effect Sizes:\n",
      "   Cohen's d = 0.2104\n",
      "   Point-biserial r = 0.0453 (p = 0.0012)\n",
      "   Mean difference = 1.633\n",
      "   Mann-Whitney r = 0.0620\n",
      "\n",
      "ðŸ¥ Clinical Interpretation:\n",
      "   Statistical: Statistically significant\n",
      "   Effect size: Small effect\n",
      "   Clinical: No clinical significance\n",
      "   Recommendation: Trivial BMI difference: 1.6 kg/mÂ²\n",
      "\n",
      "ðŸ“‹ CONTINUOUS HYPOTHESIS TESTING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "âœ… SIGNIFICANT ASSOCIATIONS (p < 0.05):\n",
      "Variable             p-value    Cohen's d    Mean Diff    Clinical       \n",
      "---------------------------------------------------------------------------\n",
      "age                  0.0000     1.175        25.757       Strong         \n",
      "avg_glucose_level    0.0000     0.618        27.749       Strong         \n",
      "bmi                  0.0000     0.210        1.633        Weak           \n",
      "\n",
      "âŒ NON-SIGNIFICANT ASSOCIATIONS (p â‰¥ 0.05):\n",
      "   â€¢ id: p = 0.6423\n"
     ]
    }
   ],
   "source": [
    "# Perform continuous hypothesis testing\n",
    "continuous_tester = ContinuousHypothesisTester(df_cleaned, normality_results, show_progress=True)\n",
    "continuous_results = continuous_tester.test_continuous_associations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Multiple Testing Correction\n",
    "\n",
    "Applying appropriate corrections for multiple hypothesis testing to control family-wise error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleTestingCorrector:\n",
    "    \"\"\"\n",
    "    Apply multiple testing corrections to control Type I error rate\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, categorical_results: Dict, continuous_results: Dict, show_progress: bool = True):\n",
    "        self.categorical_results = categorical_results\n",
    "        self.continuous_results = continuous_results\n",
    "        self.show_progress = show_progress\n",
    "        self.correction_results = {}\n",
    "    \n",
    "    def apply_multiple_testing_correction(self, alpha: float = 0.05) -> Dict:\n",
    "        \"\"\"\n",
    "        Apply multiple testing corrections\n",
    "        \"\"\"\n",
    "        if self.show_progress:\n",
    "            print(\"=\"*80)\n",
    "            print(\"ðŸ”¬ MULTIPLE TESTING CORRECTION\")\n",
    "            print(\"=\"*80)\n",
    "        \n",
    "        # Collect all p-values and test information\n",
    "        all_tests = []\n",
    "        \n",
    "        # Categorical tests\n",
    "        for var, results in self.categorical_results.items():\n",
    "            if 'chi_square' in results['tests']:\n",
    "                p_value = results['tests']['chi_square']['p_value']\n",
    "                all_tests.append({\n",
    "                    'variable': var,\n",
    "                    'test_type': 'Chi-square',\n",
    "                    'original_p': p_value,\n",
    "                    'category': 'categorical'\n",
    "                })\n",
    "        \n",
    "        # Continuous tests\n",
    "        for var, results in self.continuous_results.items():\n",
    "            # Use Mann-Whitney as primary test (more robust)\n",
    "            if 'mann_whitney' in results['tests']:\n",
    "                p_value = results['tests']['mann_whitney']['p_value']\n",
    "                test_type = 'Mann-Whitney U'\n",
    "            elif 't_test' in results['tests']:\n",
    "                p_value = results['tests']['t_test']['p_value']\n",
    "                test_type = 't-test'\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            all_tests.append({\n",
    "                'variable': var,\n",
    "                'test_type': test_type,\n",
    "                'original_p': p_value,\n",
    "                'category': 'continuous'\n",
    "            })\n",
    "        \n",
    "        if not all_tests:\n",
    "            if self.show_progress:\n",
    "                print(\"âŒ No test results available for correction\")\n",
    "            return {}\n",
    "        \n",
    "        # Extract p-values\n",
    "        p_values = [test['original_p'] for test in all_tests]\n",
    "        \n",
    "        if self.show_progress:\n",
    "            print(f\"Total tests performed: {len(all_tests)}\")\n",
    "            print(f\"Original significance level (Î±): {alpha}\")\n",
    "        \n",
    "        # Apply different correction methods\n",
    "        corrections = {}\n",
    "        \n",
    "        # 1. Bonferroni correction\n",
    "        bonferroni_alpha = alpha / len(p_values)\n",
    "        bonferroni_significant = [p < bonferroni_alpha for p in p_values]\n",
    "        \n",
    "        corrections['bonferroni'] = {\n",
    "            'corrected_alpha': bonferroni_alpha,\n",
    "            'significant': bonferroni_significant,\n",
    "            'method_description': 'Conservative family-wise error rate control'\n",
    "        }\n",
    "        \n",
    "        # 2. Holm-Bonferroni correction\n",
    "        try:\n",
    "            holm_rejected, holm_p_corrected, _, holm_alpha = multipletests(p_values, alpha=alpha, method='holm')\n",
    "            corrections['holm'] = {\n",
    "                'rejected': holm_rejected,\n",
    "                'corrected_p': holm_p_corrected,\n",
    "                'method_description': 'Step-down Bonferroni method'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âš ï¸  Holm correction failed: {e}\")\n",
    "        \n",
    "        # 3. Benjamini-Hochberg (FDR) correction\n",
    "        try:\n",
    "            fdr_rejected, fdr_p_corrected, _, fdr_alpha = multipletests(p_values, alpha=alpha, method='fdr_bh')\n",
    "            corrections['benjamini_hochberg'] = {\n",
    "                'rejected': fdr_rejected,\n",
    "                'corrected_p': fdr_p_corrected,\n",
    "                'method_description': 'False Discovery Rate control (less conservative)'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âš ï¸  FDR correction failed: {e}\")\n",
    "        \n",
    "        # 4. Sidak correction\n",
    "        try:\n",
    "            sidak_rejected, sidak_p_corrected, _, sidak_alpha = multipletests(p_values, alpha=alpha, method='sidak')\n",
    "            corrections['sidak'] = {\n",
    "                'rejected': sidak_rejected,\n",
    "                'corrected_p': sidak_p_corrected,\n",
    "                'method_description': 'Less conservative than Bonferroni'\n",
    "            }\n",
    "        except Exception as e:\n",
    "            if self.show_progress:\n",
    "                print(f\"âš ï¸  Sidak correction failed: {e}\")\n",
    "        \n",
    "        # Combine results\n",
    "        for i, test in enumerate(all_tests):\n",
    "            test_result = {\n",
    "                'variable': test['variable'],\n",
    "                'test_type': test['test_type'],\n",
    "                'category': test['category'],\n",
    "                'original_p': test['original_p'],\n",
    "                'original_significant': test['original_p'] < alpha\n",
    "            }\n",
    "            \n",
    "            # Add correction results\n",
    "            for method, correction in corrections.items():\n",
    "                if method == 'bonferroni':\n",
    "                    test_result[f'{method}_significant'] = correction['significant'][i]\n",
    "                    test_result[f'{method}_alpha'] = correction['corrected_alpha']\n",
    "                else:\n",
    "                    if 'rejected' in correction:\n",
    "                        test_result[f'{method}_significant'] = correction['rejected'][i]\n",
    "                        test_result[f'{method}_corrected_p'] = correction['corrected_p'][i]\n",
    "            \n",
    "            self.correction_results[test['variable']] = test_result\n",
    "        \n",
    "        # Print results\n",
    "        if self.show_progress:\n",
    "            self._print_correction_summary(corrections, alpha)\n",
    "        \n",
    "        return self.correction_results\n",
    "    \n",
    "    def _print_correction_summary(self, corrections: Dict, alpha: float):\n",
    "        \"\"\"\n",
    "        Print comprehensive summary of multiple testing corrections\n",
    "        \"\"\"\n",
    "        print(f\"\\nðŸ“Š CORRECTION METHODS APPLIED:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        for method, correction in corrections.items():\n",
    "            print(f\"\\n{method.upper()}:\")\n",
    "            print(f\"   Description: {correction['method_description']}\")\n",
    "            \n",
    "            if method == 'bonferroni':\n",
    "                print(f\"   Corrected Î±: {correction['corrected_alpha']:.6f}\")\n",
    "                sig_count = sum(correction['significant'])\n",
    "            else:\n",
    "                if 'rejected' in correction:\n",
    "                    sig_count = sum(correction['rejected'])\n",
    "                else:\n",
    "                    sig_count = 0\n",
    "            \n",
    "            print(f\"   Significant tests: {sig_count}/{len(self.correction_results)}\")\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ DETAILED RESULTS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{'Variable':<20} {'Test':<15} {'Original p':<12} {'Original':<10} {'Bonferroni':<12} {'FDR':<8}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Sort by original p-value\n",
    "        sorted_results = sorted(self.correction_results.values(), key=lambda x: x['original_p'])\n",
    "        \n",
    "        for result in sorted_results:\n",
    "            var = result['variable']\n",
    "            test_type = result['test_type']\n",
    "            orig_p = result['original_p']\n",
    "            orig_sig = \"âœ…\" if result['original_significant'] else \"âŒ\"\n",
    "            \n",
    "            bonf_sig = \"âœ…\" if result.get('bonferroni_significant', False) else \"âŒ\"\n",
    "            fdr_sig = \"âœ…\" if result.get('benjamini_hochberg_significant', False) else \"âŒ\"\n",
    "            \n",
    "            print(f\"{var:<20} {test_type:<15} {orig_p:<12.4f} {orig_sig:<10} {bonf_sig:<12} {fdr_sig:<8}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        original_sig = sum([r['original_significant'] for r in self.correction_results.values()])\n",
    "        bonf_sig = sum([r.get('bonferroni_significant', False) for r in self.correction_results.values()])\n",
    "        fdr_sig = sum([r.get('benjamini_hochberg_significant', False) for r in self.correction_results.values()])\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ SUMMARY:\")\n",
    "        print(f\"   Original significance: {original_sig}/{len(self.correction_results)} tests\")\n",
    "        print(f\"   After Bonferroni: {bonf_sig}/{len(self.correction_results)} tests\")\n",
    "        print(f\"   After FDR: {fdr_sig}/{len(self.correction_results)} tests\")\n",
    "        \n",
    "        # Recommendations\n",
    "        print(f\"\\nðŸ’¡ RECOMMENDATIONS:\")\n",
    "        if bonf_sig > 0:\n",
    "            print(f\"   âœ… {bonf_sig} variables survive conservative Bonferroni correction\")\n",
    "            print(f\"   â†’ These represent the strongest evidence for association\")\n",
    "        \n",
    "        if fdr_sig > bonf_sig:\n",
    "            print(f\"   âš ï¸  {fdr_sig - bonf_sig} additional variables significant with FDR\")\n",
    "            print(f\"   â†’ Consider these for exploratory analysis\")\n",
    "        \n",
    "        if original_sig > fdr_sig:\n",
    "            print(f\"   âš ï¸  {original_sig - fdr_sig} variables significant only without correction\")\n",
    "            print(f\"   â†’ May represent false discoveries due to multiple testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”¬ MULTIPLE TESTING CORRECTION\n",
      "================================================================================\n",
      "Total tests performed: 11\n",
      "Original significance level (Î±): 0.05\n",
      "\n",
      "ðŸ“Š CORRECTION METHODS APPLIED:\n",
      "--------------------------------------------------\n",
      "\n",
      "BONFERRONI:\n",
      "   Description: Conservative family-wise error rate control\n",
      "   Corrected Î±: 0.004545\n",
      "   Significant tests: 3/11\n",
      "\n",
      "HOLM:\n",
      "   Description: Step-down Bonferroni method\n",
      "   Significant tests: 3/11\n",
      "\n",
      "BENJAMINI_HOCHBERG:\n",
      "   Description: False Discovery Rate control (less conservative)\n",
      "   Significant tests: 3/11\n",
      "\n",
      "SIDAK:\n",
      "   Description: Less conservative than Bonferroni\n",
      "   Significant tests: 3/11\n",
      "\n",
      "ðŸ“‹ DETAILED RESULTS:\n",
      "--------------------------------------------------------------------------------\n",
      "Variable             Test            Original p   Original   Bonferroni   FDR     \n",
      "--------------------------------------------------------------------------------\n",
      "gender               Chi-square      nan          âŒ          âŒ            âŒ       \n",
      "hypertension         Chi-square      nan          âŒ          âŒ            âŒ       \n",
      "heart_disease        Chi-square      nan          âŒ          âŒ            âŒ       \n",
      "ever_married         Chi-square      nan          âŒ          âŒ            âŒ       \n",
      "work_type            Chi-square      nan          âŒ          âŒ            âŒ       \n",
      "Residence_type       Chi-square      nan          âŒ          âŒ            âŒ       \n",
      "smoking_status       Chi-square      nan          âŒ          âŒ            âŒ       \n",
      "age                  Mann-Whitney U  0.0000       âœ…          âœ…            âœ…       \n",
      "avg_glucose_level    Mann-Whitney U  0.0000       âœ…          âœ…            âœ…       \n",
      "bmi                  Mann-Whitney U  0.0000       âœ…          âœ…            âœ…       \n",
      "id                   Mann-Whitney U  0.6423       âŒ          âŒ            âŒ       \n",
      "\n",
      "ðŸ“ˆ SUMMARY:\n",
      "   Original significance: 3/11 tests\n",
      "   After Bonferroni: 3/11 tests\n",
      "   After FDR: 3/11 tests\n",
      "\n",
      "ðŸ’¡ RECOMMENDATIONS:\n",
      "   âœ… 3 variables survive conservative Bonferroni correction\n",
      "   â†’ These represent the strongest evidence for association\n"
     ]
    }
   ],
   "source": [
    "# Apply multiple testing correction\n",
    "corrector = MultipleTestingCorrector(categorical_results, continuous_results, show_progress=True)\n",
    "correction_results = corrector.apply_multiple_testing_correction(alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Comprehensive Results Visualization\n",
    "\n",
    "Creating comprehensive visualizations to illustrate hypothesis testing findings and statistical evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hypothesis_testing_visualizations(categorical_results, continuous_results, correction_results):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations for hypothesis testing results\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ“Š CREATING HYPOTHESIS TESTING VISUALIZATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    visualizations = {}\n",
    "    \n",
    "    # 1. P-values visualization (Volcano plot style)\n",
    "    print(\"Creating p-values visualization...\")\n",
    "    \n",
    "    # Collect data for visualization\n",
    "    plot_data = []\n",
    "    \n",
    "    # Categorical variables\n",
    "    for var, results in categorical_results.items():\n",
    "        if 'chi_square' in results['tests']:\n",
    "            p_val = results['tests']['chi_square']['p_value']\n",
    "            effect_size = results.get('effect_sizes', {}).get('cramers_v', 0)\n",
    "            \n",
    "            plot_data.append({\n",
    "                'variable': var,\n",
    "                'p_value': p_val,\n",
    "                'log_p': -np.log10(p_val),\n",
    "                'effect_size': effect_size,\n",
    "                'type': 'Categorical',\n",
    "                'significant': p_val < 0.05,\n",
    "                'bonferroni_sig': correction_results.get(var, {}).get('bonferroni_significant', False)\n",
    "            })\n",
    "    \n",
    "    # Continuous variables\n",
    "    for var, results in continuous_results.items():\n",
    "        p_val = None\n",
    "        if 'mann_whitney' in results['tests']:\n",
    "            p_val = results['tests']['mann_whitney']['p_value']\n",
    "        elif 't_test' in results['tests']:\n",
    "            p_val = results['tests']['t_test']['p_value']\n",
    "        \n",
    "        if p_val is not None:\n",
    "            effect_size = abs(results.get('effect_sizes', {}).get('cohens_d', 0))\n",
    "            \n",
    "            plot_data.append({\n",
    "                'variable': var,\n",
    "                'p_value': p_val,\n",
    "                'log_p': -np.log10(p_val),\n",
    "                'effect_size': effect_size,\n",
    "                'type': 'Continuous',\n",
    "                'significant': p_val < 0.05,\n",
    "                'bonferroni_sig': correction_results.get(var, {}).get('bonferroni_significant', False)\n",
    "            })\n",
    "    \n",
    "    if plot_data:\n",
    "        plot_df = pd.DataFrame(plot_data)\n",
    "        \n",
    "        # Create volcano plot\n",
    "        fig_volcano = px.scatter(\n",
    "            plot_df,\n",
    "            x='effect_size',\n",
    "            y='log_p',\n",
    "            color='bonferroni_sig',\n",
    "            symbol='type',\n",
    "            hover_data=['variable', 'p_value'],\n",
    "            title='Hypothesis Testing Results: Effect Size vs Statistical Significance',\n",
    "            labels={\n",
    "                'effect_size': 'Effect Size (CramÃ©r\\'s V or |Cohen\\'s d|)',\n",
    "                'log_p': '-logâ‚â‚€(p-value)',\n",
    "                'bonferroni_sig': 'Bonferroni Significant'\n",
    "            },\n",
    "            color_discrete_map={True: 'red', False: 'lightblue'}\n",
    "        )\n",
    "        \n",
    "        # Add significance lines\n",
    "        fig_volcano.add_hline(y=-np.log10(0.05), line_dash=\"dash\", line_color=\"red\", \n",
    "                             annotation_text=\"p = 0.05\")\n",
    "        fig_volcano.add_hline(y=-np.log10(0.05/len(plot_data)), line_dash=\"dash\", line_color=\"orange\",\n",
    "                             annotation_text=\"Bonferroni corrected\")\n",
    "        fig_volcano.add_vline(x=0.3, line_dash=\"dash\", line_color=\"green\",\n",
    "                             annotation_text=\"Medium effect\")\n",
    "        \n",
    "        fig_volcano.update_layout(height=600, width=800)\n",
    "        visualizations['volcano_plot'] = fig_volcano\n",
    "        fig_volcano.show()\n",
    "    \n",
    "    # 2. Effect sizes comparison\n",
    "    print(\"Creating effect sizes comparison...\")\n",
    "    \n",
    "    effect_data = []\n",
    "    for var, results in categorical_results.items():\n",
    "        if 'effect_sizes' in results:\n",
    "            if 'odds_ratio' in results['effect_sizes']:\n",
    "                or_val = results['effect_sizes']['odds_ratio']\n",
    "                effect_data.append({\n",
    "                    'variable': var,\n",
    "                    'effect_measure': 'Odds Ratio',\n",
    "                    'effect_value': or_val,\n",
    "                    'log_effect': np.log(or_val) if or_val > 0 else 0,\n",
    "                    'type': 'Categorical',\n",
    "                    'significant': results['tests']['chi_square']['p_value'] < 0.05\n",
    "                })\n",
    "    \n",
    "    for var, results in continuous_results.items():\n",
    "        if 'effect_sizes' in results:\n",
    "            cohens_d = results['effect_sizes'].get('cohens_d', 0)\n",
    "            effect_data.append({\n",
    "                'variable': var,\n",
    "                'effect_measure': 'Cohen\\'s d',\n",
    "                'effect_value': abs(cohens_d),\n",
    "                'log_effect': cohens_d,  # Keep sign for Cohen's d\n",
    "                'type': 'Continuous',\n",
    "                'significant': results['tests'].get('mann_whitney', {}).get('p_value', 1) < 0.05 or \n",
    "                              results['tests'].get('t_test', {}).get('p_value', 1) < 0.05\n",
    "            })\n",
    "    \n",
    "    if effect_data:\n",
    "        effect_df = pd.DataFrame(effect_data)\n",
    "        \n",
    "        # Separate plots for different effect measures\n",
    "        fig_effects = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=['Odds Ratios (Categorical)', 'Cohen\\'s d (Continuous)'],\n",
    "            specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "        )\n",
    "        \n",
    "        # Odds ratios\n",
    "        or_data = effect_df[effect_df['effect_measure'] == 'Odds Ratio']\n",
    "        if len(or_data) > 0:\n",
    "            colors = ['red' if sig else 'lightblue' for sig in or_data['significant']]\n",
    "            fig_effects.add_trace(\n",
    "                go.Bar(\n",
    "                    x=or_data['variable'],\n",
    "                    y=or_data['effect_value'],\n",
    "                    name='Odds Ratio',\n",
    "                    marker_color=colors,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            fig_effects.add_hline(y=1, line_dash=\"dash\", line_color=\"black\", row=1, col=1)\n",
    "        \n",
    "        # Cohen's d\n",
    "        cohens_data = effect_df[effect_df['effect_measure'] == 'Cohen\\'s d']\n",
    "        if len(cohens_data) > 0:\n",
    "            colors = ['red' if sig else 'lightblue' for sig in cohens_data['significant']]\n",
    "            fig_effects.add_trace(\n",
    "                go.Bar(\n",
    "                    x=cohens_data['variable'],\n",
    "                    y=cohens_data['log_effect'],\n",
    "                    name='Cohen\\'s d',\n",
    "                    marker_color=colors,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=2\n",
    "            )\n",
    "            fig_effects.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", row=1, col=2)\n",
    "            fig_effects.add_hline(y=0.2, line_dash=\"dot\", line_color=\"green\", row=1, col=2)\n",
    "            fig_effects.add_hline(y=0.5, line_dash=\"dot\", line_color=\"orange\", row=1, col=2)\n",
    "            fig_effects.add_hline(y=0.8, line_dash=\"dot\", line_color=\"red\", row=1, col=2)\n",
    "        \n",
    "        fig_effects.update_layout(\n",
    "            title='Effect Sizes by Variable Type',\n",
    "            height=500,\n",
    "            showlegend=False\n",
    "        )\n",
    "        fig_effects.update_xaxes(tickangle=45)\n",
    "        \n",
    "        visualizations['effect_sizes'] = fig_effects\n",
    "        fig_effects.show()\n",
    "    \n",
    "    # 3. Multiple testing correction comparison\n",
    "    print(\"Creating multiple testing correction visualization...\")\n",
    "    \n",
    "    if correction_results:\n",
    "        correction_data = []\n",
    "        for var, results in correction_results.items():\n",
    "            correction_data.append({\n",
    "                'variable': var,\n",
    "                'original_p': results['original_p'],\n",
    "                'original_sig': results['original_significant'],\n",
    "                'bonferroni_sig': results.get('bonferroni_significant', False),\n",
    "                'fdr_sig': results.get('benjamini_hochberg_significant', False)\n",
    "            })\n",
    "        \n",
    "        correction_df = pd.DataFrame(correction_data)\n",
    "        correction_df = correction_df.sort_values('original_p')\n",
    "        \n",
    "        # Create correction comparison plot\n",
    "        fig_correction = go.Figure()\n",
    "        \n",
    "        # Add bars for each correction method\n",
    "        x_pos = list(range(len(correction_df)))\n",
    "        \n",
    "        fig_correction.add_trace(go.Bar(\n",
    "            x=correction_df['variable'],\n",
    "            y=[1 if sig else 0 for sig in correction_df['original_sig']],\n",
    "            name='Original (Î± = 0.05)',\n",
    "            marker_color='lightblue',\n",
    "            opacity=0.7\n",
    "        ))\n",
    "        \n",
    "        fig_correction.add_trace(go.Bar(\n",
    "            x=correction_df['variable'],\n",
    "            y=[1 if sig else 0 for sig in correction_df['bonferroni_sig']],\n",
    "            name='Bonferroni',\n",
    "            marker_color='red',\n",
    "            opacity=0.7\n",
    "        ))\n",
    "        \n",
    "        fig_correction.add_trace(go.Bar(\n",
    "            x=correction_df['variable'],\n",
    "            y=[1 if sig else 0 for sig in correction_df['fdr_sig']],\n",
    "            name='FDR (Benjamini-Hochberg)',\n",
    "            marker_color='orange',\n",
    "            opacity=0.7\n",
    "        ))\n",
    "        \n",
    "        fig_correction.update_layout(\n",
    "            title='Multiple Testing Correction Comparison',\n",
    "            xaxis_title='Variables',\n",
    "            yaxis_title='Significant (1) / Not Significant (0)',\n",
    "            barmode='group',\n",
    "            height=500,\n",
    "            xaxis_tickangle=45\n",
    "        )\n",
    "        \n",
    "        visualizations['correction_comparison'] = fig_correction\n",
    "        fig_correction.show()\n",
    "    \n",
    "    # 4. Clinical significance assessment\n",
    "    print(\"Creating clinical significance assessment...\")\n",
    "    \n",
    "    clinical_data = []\n",
    "    \n",
    "    # Collect clinical significance data\n",
    "    for var, results in categorical_results.items():\n",
    "        if 'clinical_interpretation' in results:\n",
    "            clinical_sig = results['clinical_interpretation']['clinical_significance']\n",
    "            stat_sig = results['clinical_interpretation']['statistical_significance']\n",
    "            \n",
    "            clinical_score = 0\n",
    "            if 'Strong' in clinical_sig:\n",
    "                clinical_score = 3\n",
    "            elif 'Moderate' in clinical_sig:\n",
    "                clinical_score = 2\n",
    "            elif 'Weak' in clinical_sig:\n",
    "                clinical_score = 1\n",
    "            \n",
    "            clinical_data.append({\n",
    "                'variable': var,\n",
    "                'type': 'Categorical',\n",
    "                'statistical_significance': 1 if 'Significant' in stat_sig else 0,\n",
    "                'clinical_significance': clinical_score,\n",
    "                'category': clinical_sig\n",
    "            })\n",
    "    \n",
    "    for var, results in continuous_results.items():\n",
    "        if 'clinical_interpretation' in results:\n",
    "            clinical_sig = results['clinical_interpretation']['clinical_significance']\n",
    "            stat_sig = results['clinical_interpretation']['statistical_significance']\n",
    "            \n",
    "            clinical_score = 0\n",
    "            if 'Strong' in clinical_sig:\n",
    "                clinical_score = 3\n",
    "            elif 'Moderate' in clinical_sig:\n",
    "                clinical_score = 2\n",
    "            elif 'Weak' in clinical_sig:\n",
    "                clinical_score = 1\n",
    "            \n",
    "            clinical_data.append({\n",
    "                'variable': var,\n",
    "                'type': 'Continuous',\n",
    "                'statistical_significance': 1 if 'Significant' in stat_sig else 0,\n",
    "                'clinical_significance': clinical_score,\n",
    "                'category': clinical_sig\n",
    "            })\n",
    "    \n",
    "    if clinical_data:\n",
    "        clinical_df = pd.DataFrame(clinical_data)\n",
    "        \n",
    "        # Create clinical vs statistical significance scatter plot\n",
    "        fig_clinical = px.scatter(\n",
    "            clinical_df,\n",
    "            x='statistical_significance',\n",
    "            y='clinical_significance',\n",
    "            color='type',\n",
    "            symbol='type',\n",
    "            hover_data=['variable', 'category'],\n",
    "            title='Statistical vs Clinical Significance',\n",
    "            labels={\n",
    "                'statistical_significance': 'Statistical Significance',\n",
    "                'clinical_significance': 'Clinical Significance Score'\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Add quadrant lines\n",
    "        fig_clinical.add_vline(x=0.5, line_dash=\"dash\", line_color=\"gray\")\n",
    "        fig_clinical.add_hline(y=1.5, line_dash=\"dash\", line_color=\"gray\")\n",
    "        \n",
    "        # Add quadrant labels\n",
    "        fig_clinical.add_annotation(x=0.25, y=2.5, text=\"Clinically<br>Important<br>Only\", showarrow=False)\n",
    "        fig_clinical.add_annotation(x=0.75, y=2.5, text=\"Both<br>Statistically &<br>Clinically<br>Significant\", showarrow=False)\n",
    "        fig_clinical.add_annotation(x=0.25, y=0.5, text=\"Neither<br>Significant\", showarrow=False)\n",
    "        fig_clinical.add_annotation(x=0.75, y=0.5, text=\"Statistically<br>Significant<br>Only\", showarrow=False)\n",
    "        \n",
    "        fig_clinical.update_layout(height=600)\n",
    "        visualizations['clinical_significance'] = fig_clinical\n",
    "        fig_clinical.show()\n",
    "    \n",
    "    print(\"âœ… All visualizations created successfully!\")\n",
    "    return visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ“Š CREATING HYPOTHESIS TESTING VISUALIZATIONS\n",
      "================================================================================\n",
      "Creating p-values visualization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "gender",
           null
          ],
          [
           "hypertension",
           null
          ],
          [
           "heart_disease",
           null
          ],
          [
           "ever_married",
           null
          ],
          [
           "work_type",
           null
          ],
          [
           "Residence_type",
           null
          ],
          [
           "smoking_status",
           null
          ]
         ],
         "hovertemplate": "Bonferroni Significant=False<br>type=Categorical<br>Effect Size (CramÃ©r's V or |Cohen's d|)=%{x}<br>-logâ‚â‚€(p-value)=%{y}<br>variable=%{customdata[0]}<br>p_value=%{customdata[1]}<extra></extra>",
         "legendgroup": "False, Categorical",
         "marker": {
          "color": "lightblue",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "False, Categorical",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8AAAAAAAD4fwAAAAAAAPh/AAAAAAAA+H8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "id",
           0.6422754428825588
          ]
         ],
         "hovertemplate": "Bonferroni Significant=False<br>type=Continuous<br>Effect Size (CramÃ©r's V or |Cohen's d|)=%{x}<br>-logâ‚â‚€(p-value)=%{y}<br>variable=%{customdata[0]}<br>p_value=%{customdata[1]}<extra></extra>",
         "legendgroup": "False, Continuous",
         "marker": {
          "color": "lightblue",
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "False, Continuous",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "30HJY8Jgnj8=",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "LUUDf5acyD8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "age",
           3.726634665900012e-71
          ],
          [
           "avg_glucose_level",
           3.6403672710893244e-9
          ],
          [
           "bmi",
           0.000009469535896920327
          ]
         ],
         "hovertemplate": "Bonferroni Significant=True<br>type=Continuous<br>Effect Size (CramÃ©r's V or |Cohen's d|)=%{x}<br>-logâ‚â‚€(p-value)=%{y}<br>variable=%{customdata[0]}<br>p_value=%{customdata[1]}<extra></extra>",
         "legendgroup": "True, Continuous",
         "marker": {
          "color": "red",
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "True, Continuous",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "vNxeKALM8j/HqtGxvcfjP2+Jkn9L78o/",
          "dtype": "f8"
         },
         "xaxis": "x",
         "y": {
          "bdata": "ZBqUi2+bUUDjXoGTseAgQPx0aEo9GBRA",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "p = 0.05",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 1.3010299956639813,
          "yanchor": "bottom",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "Bonferroni corrected",
          "x": 1,
          "xanchor": "right",
          "xref": "x domain",
          "y": 2.342422680822206,
          "yanchor": "bottom",
          "yref": "y"
         },
         {
          "showarrow": false,
          "text": "Medium effect",
          "x": 0.3,
          "xanchor": "left",
          "xref": "x",
          "y": 1,
          "yanchor": "top",
          "yref": "y domain"
         }
        ],
        "height": 600,
        "legend": {
         "title": {
          "text": "Bonferroni Significant, type"
         },
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "color": "red",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 1.3010299956639813,
          "y1": 1.3010299956639813,
          "yref": "y"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 2.342422680822206,
          "y1": 2.342422680822206,
          "yref": "y"
         },
         {
          "line": {
           "color": "green",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0.3,
          "x1": 0.3,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Hypothesis Testing Results: Effect Size vs Statistical Significance"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Effect Size (CramÃ©r's V or |Cohen's d|)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "-logâ‚â‚€(p-value)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating effect sizes comparison...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "lightblue",
           "red",
           "red",
           "red"
          ]
         },
         "name": "Cohen's d",
         "showlegend": false,
         "type": "bar",
         "x": [
          "id",
          "age",
          "avg_glucose_level",
          "bmi"
         ],
         "xaxis": "x2",
         "y": {
          "bdata": "30HJY8Jgnj+83F4oAszyP8eq0bG9x+M/b4mSf0vvyj8=",
          "dtype": "f8"
         },
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Odds Ratios (Categorical)",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Cohen's d (Continuous)",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "shapes": [
         {
          "line": {
           "color": "black",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x2 domain",
          "y0": 0,
          "y1": 0,
          "yref": "y2"
         },
         {
          "line": {
           "color": "green",
           "dash": "dot"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x2 domain",
          "y0": 0.2,
          "y1": 0.2,
          "yref": "y2"
         },
         {
          "line": {
           "color": "orange",
           "dash": "dot"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x2 domain",
          "y0": 0.5,
          "y1": 0.5,
          "yref": "y2"
         },
         {
          "line": {
           "color": "red",
           "dash": "dot"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x2 domain",
          "y0": 0.8,
          "y1": 0.8,
          "yref": "y2"
         }
        ],
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Effect Sizes by Variable Type"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "tickangle": 45
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "tickangle": 45
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating multiple testing correction visualization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "lightblue"
         },
         "name": "Original (Î± = 0.05)",
         "opacity": 0.7,
         "type": "bar",
         "x": [
          "age",
          "avg_glucose_level",
          "bmi",
          "id",
          "gender",
          "hypertension",
          "heart_disease",
          "ever_married",
          "work_type",
          "Residence_type",
          "smoking_status"
         ],
         "y": [
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "red"
         },
         "name": "Bonferroni",
         "opacity": 0.7,
         "type": "bar",
         "x": [
          "age",
          "avg_glucose_level",
          "bmi",
          "id",
          "gender",
          "hypertension",
          "heart_disease",
          "ever_married",
          "work_type",
          "Residence_type",
          "smoking_status"
         ],
         "y": [
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        },
        {
         "marker": {
          "color": "orange"
         },
         "name": "FDR (Benjamini-Hochberg)",
         "opacity": 0.7,
         "type": "bar",
         "x": [
          "age",
          "avg_glucose_level",
          "bmi",
          "id",
          "gender",
          "hypertension",
          "heart_disease",
          "ever_married",
          "work_type",
          "Residence_type",
          "smoking_status"
         ],
         "y": [
          1,
          1,
          1,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Multiple Testing Correction Comparison"
        },
        "xaxis": {
         "tickangle": 45,
         "title": {
          "text": "Variables"
         }
        },
        "yaxis": {
         "title": {
          "text": "Significant (1) / Not Significant (0)"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating clinical significance assessment...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "gender",
           "No clinical significance"
          ],
          [
           "hypertension",
           "No clinical significance"
          ],
          [
           "heart_disease",
           "No clinical significance"
          ],
          [
           "ever_married",
           "No clinical significance"
          ],
          [
           "work_type",
           "No clinical significance"
          ],
          [
           "Residence_type",
           "No clinical significance"
          ],
          [
           "smoking_status",
           "No clinical significance"
          ]
         ],
         "hovertemplate": "type=Categorical<br>Statistical Significance=%{x}<br>Clinical Significance Score=%{y}<br>variable=%{customdata[0]}<br>category=%{customdata[1]}<extra></extra>",
         "legendgroup": "Categorical",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "Categorical",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAA==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAAAAAAA==",
          "dtype": "i1"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "id",
           "No clinical significance"
          ],
          [
           "age",
           "Strong clinical significance"
          ],
          [
           "avg_glucose_level",
           "Moderate clinical significance"
          ],
          [
           "bmi",
           "No clinical significance"
          ]
         ],
         "hovertemplate": "type=Continuous<br>Statistical Significance=%{x}<br>Clinical Significance Score=%{y}<br>variable=%{customdata[0]}<br>category=%{customdata[1]}<extra></extra>",
         "legendgroup": "Continuous",
         "marker": {
          "color": "#EF553B",
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "Continuous",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "AAAAAA==",
          "dtype": "i1"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAMCAA==",
          "dtype": "i1"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Clinically<br>Important<br>Only",
          "x": 0.25,
          "y": 2.5
         },
         {
          "showarrow": false,
          "text": "Both<br>Statistically &<br>Clinically<br>Significant",
          "x": 0.75,
          "y": 2.5
         },
         {
          "showarrow": false,
          "text": "Neither<br>Significant",
          "x": 0.25,
          "y": 0.5
         },
         {
          "showarrow": false,
          "text": "Statistically<br>Significant<br>Only",
          "x": 0.75,
          "y": 0.5
         }
        ],
        "height": 600,
        "legend": {
         "title": {
          "text": "type"
         },
         "tracegroupgap": 0
        },
        "shapes": [
         {
          "line": {
           "color": "gray",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0.5,
          "x1": 0.5,
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         },
         {
          "line": {
           "color": "gray",
           "dash": "dash"
          },
          "type": "line",
          "x0": 0,
          "x1": 1,
          "xref": "x domain",
          "y0": 1.5,
          "y1": 1.5,
          "yref": "y"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Statistical vs Clinical Significance"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Statistical Significance"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Clinical Significance Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All visualizations created successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create comprehensive visualizations\n",
    "visualizations = create_hypothesis_testing_visualizations(categorical_results, continuous_results, correction_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Final Results Summary and Clinical Interpretation\n",
    "\n",
    "Comprehensive summary of all hypothesis testing results with clinical recommendations and evidence-based conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_comprehensive_hypothesis_testing_report(categorical_results, continuous_results, correction_results):\n",
    "    \"\"\"\n",
    "    Generate comprehensive final report with clinical interpretation\n",
    "    \"\"\"\n",
    "    print(\"=\"*100)\n",
    "    print(\"ðŸ“‹ COMPREHENSIVE HYPOTHESIS TESTING REPORT\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Header information\n",
    "    print(f\"\\nStroke Prediction Analysis - Statistical Hypothesis Testing\")\n",
    "    print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Methodology: Rigorous statistical testing with medical domain validation\")\n",
    "    \n",
    "    # Collect all significant findings\n",
    "    strong_evidence = []\n",
    "    moderate_evidence = []\n",
    "    weak_evidence = []\n",
    "    no_evidence = []\n",
    "    \n",
    "    total_tests = len(categorical_results) + len(continuous_results)\n",
    "    \n",
    "    print(f\"\\nðŸ”¬ ANALYSIS OVERVIEW:\")\n",
    "    print(f\"   Total variables tested: {total_tests}\")\n",
    "    print(f\"   Categorical variables: {len(categorical_results)}\")\n",
    "    print(f\"   Continuous variables: {len(continuous_results)}\")\n",
    "    print(f\"   Multiple testing correction: Applied (Bonferroni, FDR)\")\n",
    "    \n",
    "    # Process categorical results\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š CATEGORICAL VARIABLES ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for var, results in categorical_results.items():\n",
    "        if 'tests' in results and 'chi_square' in results['tests']:\n",
    "            test_result = results['tests']['chi_square']\n",
    "            p_value = test_result['p_value']\n",
    "            \n",
    "            # Get correction results\n",
    "            corrected = correction_results.get(var, {})\n",
    "            bonferroni_sig = corrected.get('bonferroni_significant', False)\n",
    "            fdr_sig = corrected.get('benjamini_hochberg_significant', False)\n",
    "            \n",
    "            # Get effect sizes\n",
    "            effect_sizes = results.get('effect_sizes', {})\n",
    "            odds_ratio = effect_sizes.get('odds_ratio', None)\n",
    "            cramers_v = effect_sizes.get('cramers_v', 0)\n",
    "            \n",
    "            # Get clinical interpretation\n",
    "            clinical = results.get('clinical_interpretation', {})\n",
    "            clinical_significance = clinical.get('clinical_significance', 'No clinical significance')\n",
    "            \n",
    "            print(f\"\\nðŸ“‹ {var.upper().replace('_', ' ')}\")\n",
    "            print(f\"   Test: Chi-square test of independence\")\n",
    "            print(f\"   Sample distribution:\")\n",
    "            \n",
    "            # Print contingency table summary\n",
    "            if 'contingency_table' in results:\n",
    "                ct = results['contingency_table']\n",
    "                print(f\"   â””â”€â”€ Contingency table available\")\n",
    "            \n",
    "            print(f\"   Statistical Results:\")\n",
    "            print(f\"   â”œâ”€â”€ Ï‡Â² = {test_result['statistic']:.4f}\")\n",
    "            print(f\"   â”œâ”€â”€ p-value = {p_value:.4f}\")\n",
    "            print(f\"   â”œâ”€â”€ Original significance: {'âœ… Yes' if p_value < 0.05 else 'âŒ No'}\")\n",
    "            print(f\"   â”œâ”€â”€ Bonferroni corrected: {'âœ… Yes' if bonferroni_sig else 'âŒ No'}\")\n",
    "            print(f\"   â””â”€â”€ FDR corrected: {'âœ… Yes' if fdr_sig else 'âŒ No'}\")\n",
    "            \n",
    "            print(f\"   Effect Sizes:\")\n",
    "            if odds_ratio is not None:\n",
    "                ci_lower = effect_sizes.get('or_ci_lower', 'N/A')\n",
    "                ci_upper = effect_sizes.get('or_ci_upper', 'N/A')\n",
    "                print(f\"   â”œâ”€â”€ Odds Ratio: {odds_ratio:.3f}\")\n",
    "                if ci_lower != 'N/A' and ci_upper != 'N/A':\n",
    "                    print(f\"   â”œâ”€â”€ 95% CI: [{ci_lower:.3f} - {ci_upper:.3f}]\")\n",
    "            print(f\"   â””â”€â”€ CramÃ©r's V: {cramers_v:.3f}\")\n",
    "            \n",
    "            print(f\"   Clinical Assessment:\")\n",
    "            print(f\"   â”œâ”€â”€ Clinical significance: {clinical_significance}\")\n",
    "            print(f\"   â””â”€â”€ Recommendation: {clinical.get('clinical_recommendation', 'No specific recommendation')}\")\n",
    "            \n",
    "            # Classify evidence strength\n",
    "            if bonferroni_sig and odds_ratio is not None:\n",
    "                if odds_ratio > 2.0:\n",
    "                    strong_evidence.append({\n",
    "                        'variable': var,\n",
    "                        'type': 'categorical',\n",
    "                        'p_value': p_value,\n",
    "                        'effect_size': odds_ratio,\n",
    "                        'effect_type': 'Odds Ratio',\n",
    "                        'clinical_significance': clinical_significance\n",
    "                    })\n",
    "                elif odds_ratio > 1.5:\n",
    "                    moderate_evidence.append({\n",
    "                        'variable': var,\n",
    "                        'type': 'categorical',\n",
    "                        'p_value': p_value,\n",
    "                        'effect_size': odds_ratio,\n",
    "                        'effect_type': 'Odds Ratio',\n",
    "                        'clinical_significance': clinical_significance\n",
    "                    })\n",
    "                else:\n",
    "                    weak_evidence.append({\n",
    "                        'variable': var,\n",
    "                        'type': 'categorical',\n",
    "                        'p_value': p_value,\n",
    "                        'effect_size': odds_ratio,\n",
    "                        'effect_type': 'Odds Ratio',\n",
    "                        'clinical_significance': clinical_significance\n",
    "                    })\n",
    "            elif fdr_sig:\n",
    "                weak_evidence.append({\n",
    "                    'variable': var,\n",
    "                    'type': 'categorical',\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': odds_ratio or cramers_v,\n",
    "                    'effect_type': 'Odds Ratio' if odds_ratio else 'CramÃ©r\\'s V',\n",
    "                    'clinical_significance': clinical_significance\n",
    "                })\n",
    "            else:\n",
    "                no_evidence.append({\n",
    "                    'variable': var,\n",
    "                    'type': 'categorical',\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': odds_ratio or cramers_v,\n",
    "                    'effect_type': 'Odds Ratio' if odds_ratio else 'CramÃ©r\\'s V',\n",
    "                    'clinical_significance': clinical_significance\n",
    "                })\n",
    "    \n",
    "    # Process continuous results\n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“ˆ CONTINUOUS VARIABLES ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for var, results in continuous_results.items():\n",
    "        # Get primary test result (prefer Mann-Whitney for robustness)\n",
    "        test_result = None\n",
    "        test_name = \"\"\n",
    "        \n",
    "        if 'mann_whitney' in results['tests']:\n",
    "            test_result = results['tests']['mann_whitney']\n",
    "            test_name = \"Mann-Whitney U test\"\n",
    "        elif 't_test' in results['tests']:\n",
    "            test_result = results['tests']['t_test']\n",
    "            test_name = test_result.get('test_type', 't-test')\n",
    "        \n",
    "        if test_result is None:\n",
    "            continue\n",
    "            \n",
    "        p_value = test_result['p_value']\n",
    "        \n",
    "        # Get correction results\n",
    "        corrected = correction_results.get(var, {})\n",
    "        bonferroni_sig = corrected.get('bonferroni_significant', False)\n",
    "        fdr_sig = corrected.get('benjamini_hochberg_significant', False)\n",
    "        \n",
    "        # Get descriptive statistics\n",
    "        desc_stats = results.get('descriptive_stats', {})\n",
    "        no_stroke_stats = desc_stats.get('no_stroke', {})\n",
    "        stroke_stats = desc_stats.get('stroke', {})\n",
    "        \n",
    "        # Get effect sizes\n",
    "        effect_sizes = results.get('effect_sizes', {})\n",
    "        cohens_d = effect_sizes.get('cohens_d', 0)\n",
    "        mean_diff = effect_sizes.get('mean_difference', 0)\n",
    "        point_biserial_r = effect_sizes.get('point_biserial_r', 0)\n",
    "        \n",
    "        # Get clinical interpretation\n",
    "        clinical = results.get('clinical_interpretation', {})\n",
    "        clinical_significance = clinical.get('clinical_significance', 'No clinical significance')\n",
    "        \n",
    "        print(f\"\\nðŸ“Š {var.upper().replace('_', ' ')}\")\n",
    "        print(f\"   Test: {test_name}\")\n",
    "        print(f\"   Sample sizes: No stroke = {no_stroke_stats.get('n', 'N/A'):,}, Stroke = {stroke_stats.get('n', 'N/A'):,}\")\n",
    "        \n",
    "        print(f\"   Descriptive Statistics:\")\n",
    "        print(f\"   â”œâ”€â”€ No stroke: Mean = {no_stroke_stats.get('mean', 0):.3f}, SD = {no_stroke_stats.get('std', 0):.3f}\")\n",
    "        print(f\"   â”œâ”€â”€ Stroke: Mean = {stroke_stats.get('mean', 0):.3f}, SD = {stroke_stats.get('std', 0):.3f}\")\n",
    "        print(f\"   â””â”€â”€ Mean difference: {mean_diff:.3f}\")\n",
    "        \n",
    "        print(f\"   Statistical Results:\")\n",
    "        if 'statistic' in test_result:\n",
    "            print(f\"   â”œâ”€â”€ Test statistic = {test_result['statistic']:.4f}\")\n",
    "        print(f\"   â”œâ”€â”€ p-value = {p_value:.4f}\")\n",
    "        print(f\"   â”œâ”€â”€ Original significance: {'âœ… Yes' if p_value < 0.05 else 'âŒ No'}\")\n",
    "        print(f\"   â”œâ”€â”€ Bonferroni corrected: {'âœ… Yes' if bonferroni_sig else 'âŒ No'}\")\n",
    "        print(f\"   â””â”€â”€ FDR corrected: {'âœ… Yes' if fdr_sig else 'âŒ No'}\")\n",
    "        \n",
    "        print(f\"   Effect Sizes:\")\n",
    "        print(f\"   â”œâ”€â”€ Cohen's d: {cohens_d:.3f}\")\n",
    "        print(f\"   â”œâ”€â”€ Point-biserial r: {point_biserial_r:.3f}\")\n",
    "        print(f\"   â””â”€â”€ Mean difference: {mean_diff:.3f}\")\n",
    "        \n",
    "        print(f\"   Clinical Assessment:\")\n",
    "        print(f\"   â”œâ”€â”€ Clinical significance: {clinical_significance}\")\n",
    "        print(f\"   â””â”€â”€ Recommendation: {clinical.get('clinical_recommendation', 'No specific recommendation')}\")\n",
    "        \n",
    "        # Classify evidence strength\n",
    "        if bonferroni_sig:\n",
    "            if abs(cohens_d) >= 0.8:\n",
    "                strong_evidence.append({\n",
    "                    'variable': var,\n",
    "                    'type': 'continuous',\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': cohens_d,\n",
    "                    'effect_type': 'Cohen\\'s d',\n",
    "                    'clinical_significance': clinical_significance,\n",
    "                    'mean_difference': mean_diff\n",
    "                })\n",
    "            elif abs(cohens_d) >= 0.5:\n",
    "                moderate_evidence.append({\n",
    "                    'variable': var,\n",
    "                    'type': 'continuous',\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': cohens_d,\n",
    "                    'effect_type': 'Cohen\\'s d',\n",
    "                    'clinical_significance': clinical_significance,\n",
    "                    'mean_difference': mean_diff\n",
    "                })\n",
    "            else:\n",
    "                weak_evidence.append({\n",
    "                    'variable': var,\n",
    "                    'type': 'continuous',\n",
    "                    'p_value': p_value,\n",
    "                    'effect_size': cohens_d,\n",
    "                    'effect_type': 'Cohen\\'s d',\n",
    "                    'clinical_significance': clinical_significance,\n",
    "                    'mean_difference': mean_diff\n",
    "                })\n",
    "        elif fdr_sig:\n",
    "            weak_evidence.append({\n",
    "                'variable': var,\n",
    "                'type': 'continuous',\n",
    "                'p_value': p_value,\n",
    "                'effect_size': cohens_d,\n",
    "                'effect_type': 'Cohen\\'s d',\n",
    "                'clinical_significance': clinical_significance,\n",
    "                'mean_difference': mean_diff\n",
    "            })\n",
    "        else:\n",
    "            no_evidence.append({\n",
    "                'variable': var,\n",
    "                'type': 'continuous',\n",
    "                'p_value': p_value,\n",
    "                'effect_size': cohens_d,\n",
    "                'effect_type': 'Cohen\\'s d',\n",
    "                'clinical_significance': clinical_significance,\n",
    "                'mean_difference': mean_diff\n",
    "            })\n",
    "    \n",
    "    # Evidence Summary\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"ðŸŽ¯ EVIDENCE SUMMARY AND CLINICAL RECOMMENDATIONS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    print(f\"\\nðŸ† STRONG EVIDENCE (Bonferroni significant + large effect size):\")\n",
    "    if strong_evidence:\n",
    "        strong_evidence.sort(key=lambda x: x['p_value'])\n",
    "        for i, evidence in enumerate(strong_evidence, 1):\n",
    "            var = evidence['variable']\n",
    "            effect_val = evidence['effect_size']\n",
    "            effect_type = evidence['effect_type']\n",
    "            p_val = evidence['p_value']\n",
    "            clinical_sig = evidence['clinical_significance']\n",
    "            \n",
    "            print(f\"   {i}. {var.replace('_', ' ').title()}\")\n",
    "            print(f\"      â”œâ”€â”€ {effect_type}: {effect_val:.3f}\")\n",
    "            print(f\"      â”œâ”€â”€ p-value: {p_val:.4f}\")\n",
    "            print(f\"      â”œâ”€â”€ Clinical significance: {clinical_sig}\")\n",
    "            \n",
    "            if evidence['type'] == 'continuous' and 'mean_difference' in evidence:\n",
    "                print(f\"      â””â”€â”€ Mean difference: {evidence['mean_difference']:.3f}\")\n",
    "            else:\n",
    "                print(f\"      â””â”€â”€ Strong risk factor for stroke\")\n",
    "    else:\n",
    "        print(\"   âŒ No variables show strong evidence after conservative correction\")\n",
    "    \n",
    "    print(f\"\\nðŸ¥ˆ MODERATE EVIDENCE (Bonferroni significant + moderate effect size):\")\n",
    "    if moderate_evidence:\n",
    "        moderate_evidence.sort(key=lambda x: x['p_value'])\n",
    "        for i, evidence in enumerate(moderate_evidence, 1):\n",
    "            var = evidence['variable']\n",
    "            effect_val = evidence['effect_size']\n",
    "            effect_type = evidence['effect_type']\n",
    "            p_val = evidence['p_value']\n",
    "            clinical_sig = evidence['clinical_significance']\n",
    "            \n",
    "            print(f\"   {i}. {var.replace('_', ' ').title()}\")\n",
    "            print(f\"      â”œâ”€â”€ {effect_type}: {effect_val:.3f}\")\n",
    "            print(f\"      â”œâ”€â”€ p-value: {p_val:.4f}\")\n",
    "            print(f\"      â”œâ”€â”€ Clinical significance: {clinical_sig}\")\n",
    "            \n",
    "            if evidence['type'] == 'continuous' and 'mean_difference' in evidence:\n",
    "                print(f\"      â””â”€â”€ Mean difference: {evidence['mean_difference']:.3f}\")\n",
    "            else:\n",
    "                print(f\"      â””â”€â”€ Moderate risk factor for stroke\")\n",
    "    else:\n",
    "        print(\"   âŒ No variables show moderate evidence\")\n",
    "    \n",
    "    print(f\"\\nðŸ¥‰ WEAK EVIDENCE (FDR significant or small effect size):\")\n",
    "    if weak_evidence:\n",
    "        weak_evidence.sort(key=lambda x: x['p_value'])\n",
    "        for i, evidence in enumerate(weak_evidence, 1):\n",
    "            var = evidence['variable']\n",
    "            effect_val = evidence['effect_size']\n",
    "            effect_type = evidence['effect_type']\n",
    "            p_val = evidence['p_value']\n",
    "            \n",
    "            print(f\"   {i}. {var.replace('_', ' ').title()}\")\n",
    "            print(f\"      â”œâ”€â”€ {effect_type}: {effect_val:.3f}\")\n",
    "            print(f\"      â””â”€â”€ p-value: {p_val:.4f}\")\n",
    "    else:\n",
    "        print(\"   âŒ No variables show weak evidence\")\n",
    "    \n",
    "    print(f\"\\nâŒ NO EVIDENCE (Non-significant after correction):\")\n",
    "    if no_evidence:\n",
    "        no_evidence.sort(key=lambda x: x['p_value'])\n",
    "        for i, evidence in enumerate(no_evidence, 1):\n",
    "            var = evidence['variable']\n",
    "            p_val = evidence['p_value']\n",
    "            print(f\"   {i}. {var.replace('_', ' ').title()} (p = {p_val:.4f})\")\n",
    "    else:\n",
    "        print(\"   âœ… All variables showed some level of evidence\")\n",
    "    \n",
    "    # Clinical Recommendations\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"ðŸ¥ CLINICAL RECOMMENDATIONS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    print(f\"\\nðŸ’Š PRIMARY RISK FACTORS (Immediate clinical attention):\")\n",
    "    primary_factors = strong_evidence + moderate_evidence\n",
    "    if primary_factors:\n",
    "        for factor in primary_factors:\n",
    "            var = factor['variable']\n",
    "            clinical_sig = factor['clinical_significance']\n",
    "            \n",
    "            if var == 'age':\n",
    "                print(f\"   â€¢ AGE: Screen patients {factor.get('mean_difference', 0):.1f} years older for stroke risk\")\n",
    "            elif var == 'hypertension':\n",
    "                print(f\"   â€¢ HYPERTENSION: Critical modifiable risk factor (OR â‰ˆ {factor['effect_size']:.2f})\")\n",
    "            elif var == 'heart_disease':\n",
    "                print(f\"   â€¢ HEART DISEASE: Major cardiovascular comorbidity (OR â‰ˆ {factor['effect_size']:.2f})\")\n",
    "            elif 'glucose' in var.lower():\n",
    "                print(f\"   â€¢ GLUCOSE CONTROL: Monitor diabetic patients (Î” = {factor.get('mean_difference', 0):.1f} mg/dL)\")\n",
    "            elif 'bmi' in var.lower():\n",
    "                print(f\"   â€¢ BMI: Weight management important (Î” = {factor.get('mean_difference', 0):.1f} kg/mÂ²)\")\n",
    "            else:\n",
    "                print(f\"   â€¢ {var.upper().replace('_', ' ')}: {clinical_sig}\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  No primary risk factors identified - review inclusion criteria\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸  SECONDARY FACTORS (Monitor and consider):\")\n",
    "    if weak_evidence:\n",
    "        for factor in weak_evidence:\n",
    "            var = factor['variable']\n",
    "            print(f\"   â€¢ {var.replace('_', ' ').title()}: Consider in risk assessment\")\n",
    "    else:\n",
    "        print(\"   âœ… No secondary factors requiring monitoring\")\n",
    "    \n",
    "    print(f\"\\nðŸ” FACTORS NOT ASSOCIATED WITH STROKE:\")\n",
    "    if no_evidence:\n",
    "        for factor in no_evidence:\n",
    "            var = factor['variable']\n",
    "            print(f\"   â€¢ {var.replace('_', ' ').title()}: No evidence of association\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  All tested factors showed some association\")\n",
    "    \n",
    "    # Statistical Quality Assessment\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"ðŸ“Š STATISTICAL QUALITY ASSESSMENT\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    total_significant_original = len([1 for r in correction_results.values() if r.get('original_significant', False)])\n",
    "    total_bonferroni = len([1 for r in correction_results.values() if r.get('bonferroni_significant', False)])\n",
    "    total_fdr = len([1 for r in correction_results.values() if r.get('benjamini_hochberg_significant', False)])\n",
    "    \n",
    "    print(f\"\\nðŸ”¬ Multiple Testing Impact:\")\n",
    "    print(f\"   â”œâ”€â”€ Original significant tests: {total_significant_original}/{total_tests} ({total_significant_original/total_tests*100:.1f}%)\")\n",
    "    print(f\"   â”œâ”€â”€ After Bonferroni correction: {total_bonferroni}/{total_tests} ({total_bonferroni/total_tests*100:.1f}%)\")\n",
    "    print(f\"   â”œâ”€â”€ After FDR correction: {total_fdr}/{total_tests} ({total_fdr/total_tests*100:.1f}%)\")\n",
    "    print(f\"   â””â”€â”€ Conservative estimate: {total_bonferroni} robust associations\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Effect Size Distribution:\")\n",
    "    large_effects = len(strong_evidence)\n",
    "    medium_effects = len(moderate_evidence)\n",
    "    small_effects = len(weak_evidence)\n",
    "    \n",
    "    print(f\"   â”œâ”€â”€ Large effects (clinically important): {large_effects}\")\n",
    "    print(f\"   â”œâ”€â”€ Medium effects (moderately important): {medium_effects}\")\n",
    "    print(f\"   â”œâ”€â”€ Small effects (limited importance): {small_effects}\")\n",
    "    print(f\"   â””â”€â”€ No evidence: {len(no_evidence)}\")\n",
    "    \n",
    "    # Final Conclusions\n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"ðŸ“‹ FINAL CONCLUSIONS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ KEY FINDINGS:\")\n",
    "    if len(strong_evidence + moderate_evidence) > 0:\n",
    "        print(f\"   âœ… {len(strong_evidence + moderate_evidence)} variables show robust evidence for stroke association\")\n",
    "        print(f\"   âœ… Multiple testing corrections confirm {total_bonferroni} reliable associations\")\n",
    "        print(f\"   âœ… Effect sizes support clinical relevance for primary risk factors\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  Limited robust evidence after conservative corrections\")\n",
    "        print(f\"   âš ï¸  May indicate small effect sizes or underpowered analysis\")\n",
    "    \n",
    "    print(f\"\\nðŸ¥ CLINICAL IMPLICATIONS:\")\n",
    "    if strong_evidence:\n",
    "        print(f\"   â€¢ Prioritize screening and intervention for {len(strong_evidence)} primary risk factors\")\n",
    "        print(f\"   â€¢ Implement evidence-based prevention strategies\")\n",
    "        print(f\"   â€¢ Consider multifactorial risk assessment\")\n",
    "    \n",
    "    if moderate_evidence:\n",
    "        print(f\"   â€¢ Monitor {len(moderate_evidence)} secondary risk factors\")\n",
    "        print(f\"   â€¢ Include in comprehensive risk profiles\")\n",
    "    \n",
    "    if no_evidence:\n",
    "        print(f\"   â€¢ {len(no_evidence)} factors show no association - may exclude from routine screening\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š RESEARCH RECOMMENDATIONS:\")\n",
    "    print(f\"   â€¢ Validate findings in independent cohorts\")\n",
    "    print(f\"   â€¢ Consider interaction effects between risk factors\")\n",
    "    print(f\"   â€¢ Develop multivariable prediction models\")\n",
    "    print(f\"   â€¢ Assess temporal relationships and causality\")\n",
    "    \n",
    "    print(f\"\\nâš ï¸  LIMITATIONS:\")\n",
    "    print(f\"   â€¢ Cross-sectional analysis - no causal inference\")\n",
    "    print(f\"   â€¢ Multiple testing may increase Type II error risk\")\n",
    "    print(f\"   â€¢ Effect sizes may vary across populations\")\n",
    "    print(f\"   â€¢ Clinical thresholds based on domain expertise\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*100)\n",
    "    print(\"âœ… HYPOTHESIS TESTING ANALYSIS COMPLETE\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Return summary statistics\n",
    "    summary_stats = {\n",
    "        'total_tests': total_tests,\n",
    "        'strong_evidence': len(strong_evidence),\n",
    "        'moderate_evidence': len(moderate_evidence),\n",
    "        'weak_evidence': len(weak_evidence),\n",
    "        'no_evidence': len(no_evidence),\n",
    "        'bonferroni_significant': total_bonferroni,\n",
    "        'fdr_significant': total_fdr,\n",
    "        'primary_risk_factors': [e['variable'] for e in strong_evidence + moderate_evidence],\n",
    "        'secondary_factors': [e['variable'] for e in weak_evidence],\n",
    "        'non_significant_factors': [e['variable'] for e in no_evidence]\n",
    "    }\n",
    "    \n",
    "    return summary_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Generating comprehensive hypothesis testing report...\n",
      "====================================================================================================\n",
      "ðŸ“‹ COMPREHENSIVE HYPOTHESIS TESTING REPORT\n",
      "====================================================================================================\n",
      "\n",
      "Stroke Prediction Analysis - Statistical Hypothesis Testing\n",
      "Analysis Date: 2025-06-19 12:01:52\n",
      "Methodology: Rigorous statistical testing with medical domain validation\n",
      "\n",
      "ðŸ”¬ ANALYSIS OVERVIEW:\n",
      "   Total variables tested: 11\n",
      "   Categorical variables: 7\n",
      "   Continuous variables: 4\n",
      "   Multiple testing correction: Applied (Bonferroni, FDR)\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š CATEGORICAL VARIABLES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“‹ GENDER\n",
      "   Test: Chi-square test of independence\n",
      "   Sample distribution:\n",
      "   â””â”€â”€ Contingency table available\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Ï‡Â² = nan\n",
      "   â”œâ”€â”€ p-value = nan\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â””â”€â”€ CramÃ©r's V: nan\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“‹ HYPERTENSION\n",
      "   Test: Chi-square test of independence\n",
      "   Sample distribution:\n",
      "   â””â”€â”€ Contingency table available\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Ï‡Â² = nan\n",
      "   â”œâ”€â”€ p-value = nan\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â””â”€â”€ CramÃ©r's V: nan\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“‹ HEART DISEASE\n",
      "   Test: Chi-square test of independence\n",
      "   Sample distribution:\n",
      "   â””â”€â”€ Contingency table available\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Ï‡Â² = nan\n",
      "   â”œâ”€â”€ p-value = nan\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â””â”€â”€ CramÃ©r's V: nan\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“‹ EVER MARRIED\n",
      "   Test: Chi-square test of independence\n",
      "   Sample distribution:\n",
      "   â””â”€â”€ Contingency table available\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Ï‡Â² = nan\n",
      "   â”œâ”€â”€ p-value = nan\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â””â”€â”€ CramÃ©r's V: nan\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“‹ WORK TYPE\n",
      "   Test: Chi-square test of independence\n",
      "   Sample distribution:\n",
      "   â””â”€â”€ Contingency table available\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Ï‡Â² = nan\n",
      "   â”œâ”€â”€ p-value = nan\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â””â”€â”€ CramÃ©r's V: nan\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“‹ RESIDENCE TYPE\n",
      "   Test: Chi-square test of independence\n",
      "   Sample distribution:\n",
      "   â””â”€â”€ Contingency table available\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Ï‡Â² = nan\n",
      "   â”œâ”€â”€ p-value = nan\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â””â”€â”€ CramÃ©r's V: nan\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“‹ SMOKING STATUS\n",
      "   Test: Chi-square test of independence\n",
      "   Sample distribution:\n",
      "   â””â”€â”€ Contingency table available\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Ï‡Â² = nan\n",
      "   â”œâ”€â”€ p-value = nan\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â””â”€â”€ CramÃ©r's V: nan\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "================================================================================\n",
      "ðŸ“ˆ CONTINUOUS VARIABLES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š ID\n",
      "   Test: Mann-Whitney U test\n",
      "   Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "   Descriptive Statistics:\n",
      "   â”œâ”€â”€ No stroke: Mean = 36487.236, SD = 21120.133\n",
      "   â”œâ”€â”€ Stroke: Mean = 37115.068, SD = 21993.345\n",
      "   â””â”€â”€ Mean difference: 627.832\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Test statistic = 615742.0000\n",
      "   â”œâ”€â”€ p-value = 0.6423\n",
      "   â”œâ”€â”€ Original significance: âŒ No\n",
      "   â”œâ”€â”€ Bonferroni corrected: âŒ No\n",
      "   â””â”€â”€ FDR corrected: âŒ No\n",
      "   Effect Sizes:\n",
      "   â”œâ”€â”€ Cohen's d: 0.030\n",
      "   â”œâ”€â”€ Point-biserial r: 0.006\n",
      "   â””â”€â”€ Mean difference: 627.832\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: No evidence for clinical relevance\n",
      "\n",
      "ðŸ“Š AGE\n",
      "   Test: Mann-Whitney U test\n",
      "   Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "   Descriptive Statistics:\n",
      "   â”œâ”€â”€ No stroke: Mean = 41.972, SD = 22.292\n",
      "   â”œâ”€â”€ Stroke: Mean = 67.728, SD = 12.727\n",
      "   â””â”€â”€ Mean difference: 25.757\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Test statistic = 1010125.5000\n",
      "   â”œâ”€â”€ p-value = 0.0000\n",
      "   â”œâ”€â”€ Original significance: âœ… Yes\n",
      "   â”œâ”€â”€ Bonferroni corrected: âœ… Yes\n",
      "   â””â”€â”€ FDR corrected: âœ… Yes\n",
      "   Effect Sizes:\n",
      "   â”œâ”€â”€ Cohen's d: 1.175\n",
      "   â”œâ”€â”€ Point-biserial r: 0.245\n",
      "   â””â”€â”€ Mean difference: 25.757\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: Strong clinical significance\n",
      "   â””â”€â”€ Recommendation: Major age difference: 25.8 years\n",
      "\n",
      "ðŸ“Š AVG GLUCOSE LEVEL\n",
      "   Test: Mann-Whitney U test\n",
      "   Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "   Descriptive Statistics:\n",
      "   â”œâ”€â”€ No stroke: Mean = 104.796, SD = 43.846\n",
      "   â”œâ”€â”€ Stroke: Mean = 132.545, SD = 61.921\n",
      "   â””â”€â”€ Mean difference: 27.749\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Test statistic = 739150.0000\n",
      "   â”œâ”€â”€ p-value = 0.0000\n",
      "   â”œâ”€â”€ Original significance: âœ… Yes\n",
      "   â”œâ”€â”€ Bonferroni corrected: âœ… Yes\n",
      "   â””â”€â”€ FDR corrected: âœ… Yes\n",
      "   Effect Sizes:\n",
      "   â”œâ”€â”€ Cohen's d: 0.618\n",
      "   â”œâ”€â”€ Point-biserial r: 0.132\n",
      "   â””â”€â”€ Mean difference: 27.749\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: Moderate clinical significance\n",
      "   â””â”€â”€ Recommendation: Meaningful glucose difference: 27.7 mg/dL\n",
      "\n",
      "ðŸ“Š BMI\n",
      "   Test: Mann-Whitney U test\n",
      "   Sample sizes: No stroke = 4,861, Stroke = 249\n",
      "   Descriptive Statistics:\n",
      "   â”œâ”€â”€ No stroke: Mean = 28.877, SD = 7.838\n",
      "   â”œâ”€â”€ Stroke: Mean = 30.510, SD = 5.998\n",
      "   â””â”€â”€ Mean difference: 1.633\n",
      "   Statistical Results:\n",
      "   â”œâ”€â”€ Test statistic = 705754.0000\n",
      "   â”œâ”€â”€ p-value = 0.0000\n",
      "   â”œâ”€â”€ Original significance: âœ… Yes\n",
      "   â”œâ”€â”€ Bonferroni corrected: âœ… Yes\n",
      "   â””â”€â”€ FDR corrected: âœ… Yes\n",
      "   Effect Sizes:\n",
      "   â”œâ”€â”€ Cohen's d: 0.210\n",
      "   â”œâ”€â”€ Point-biserial r: 0.045\n",
      "   â””â”€â”€ Mean difference: 1.633\n",
      "   Clinical Assessment:\n",
      "   â”œâ”€â”€ Clinical significance: No clinical significance\n",
      "   â””â”€â”€ Recommendation: Trivial BMI difference: 1.6 kg/mÂ²\n",
      "\n",
      "====================================================================================================\n",
      "ðŸŽ¯ EVIDENCE SUMMARY AND CLINICAL RECOMMENDATIONS\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ† STRONG EVIDENCE (Bonferroni significant + large effect size):\n",
      "   1. Age\n",
      "      â”œâ”€â”€ Cohen's d: 1.175\n",
      "      â”œâ”€â”€ p-value: 0.0000\n",
      "      â”œâ”€â”€ Clinical significance: Strong clinical significance\n",
      "      â””â”€â”€ Mean difference: 25.757\n",
      "\n",
      "ðŸ¥ˆ MODERATE EVIDENCE (Bonferroni significant + moderate effect size):\n",
      "   1. Avg Glucose Level\n",
      "      â”œâ”€â”€ Cohen's d: 0.618\n",
      "      â”œâ”€â”€ p-value: 0.0000\n",
      "      â”œâ”€â”€ Clinical significance: Moderate clinical significance\n",
      "      â””â”€â”€ Mean difference: 27.749\n",
      "\n",
      "ðŸ¥‰ WEAK EVIDENCE (FDR significant or small effect size):\n",
      "   1. Bmi\n",
      "      â”œâ”€â”€ Cohen's d: 0.210\n",
      "      â””â”€â”€ p-value: 0.0000\n",
      "\n",
      "âŒ NO EVIDENCE (Non-significant after correction):\n",
      "   1. Gender (p = nan)\n",
      "   2. Hypertension (p = nan)\n",
      "   3. Heart Disease (p = nan)\n",
      "   4. Ever Married (p = nan)\n",
      "   5. Work Type (p = nan)\n",
      "   6. Residence Type (p = nan)\n",
      "   7. Smoking Status (p = nan)\n",
      "   8. Id (p = 0.6423)\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ¥ CLINICAL RECOMMENDATIONS\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ’Š PRIMARY RISK FACTORS (Immediate clinical attention):\n",
      "   â€¢ AGE: Screen patients 25.8 years older for stroke risk\n",
      "   â€¢ GLUCOSE CONTROL: Monitor diabetic patients (Î” = 27.7 mg/dL)\n",
      "\n",
      "âš ï¸  SECONDARY FACTORS (Monitor and consider):\n",
      "   â€¢ Bmi: Consider in risk assessment\n",
      "\n",
      "ðŸ” FACTORS NOT ASSOCIATED WITH STROKE:\n",
      "   â€¢ Gender: No evidence of association\n",
      "   â€¢ Hypertension: No evidence of association\n",
      "   â€¢ Heart Disease: No evidence of association\n",
      "   â€¢ Ever Married: No evidence of association\n",
      "   â€¢ Work Type: No evidence of association\n",
      "   â€¢ Residence Type: No evidence of association\n",
      "   â€¢ Smoking Status: No evidence of association\n",
      "   â€¢ Id: No evidence of association\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“Š STATISTICAL QUALITY ASSESSMENT\n",
      "====================================================================================================\n",
      "\n",
      "ðŸ”¬ Multiple Testing Impact:\n",
      "   â”œâ”€â”€ Original significant tests: 3/11 (27.3%)\n",
      "   â”œâ”€â”€ After Bonferroni correction: 3/11 (27.3%)\n",
      "   â”œâ”€â”€ After FDR correction: 3/11 (27.3%)\n",
      "   â””â”€â”€ Conservative estimate: 3 robust associations\n",
      "\n",
      "ðŸ“ˆ Effect Size Distribution:\n",
      "   â”œâ”€â”€ Large effects (clinically important): 1\n",
      "   â”œâ”€â”€ Medium effects (moderately important): 1\n",
      "   â”œâ”€â”€ Small effects (limited importance): 1\n",
      "   â””â”€â”€ No evidence: 8\n",
      "\n",
      "====================================================================================================\n",
      "ðŸ“‹ FINAL CONCLUSIONS\n",
      "====================================================================================================\n",
      "\n",
      "ðŸŽ¯ KEY FINDINGS:\n",
      "   âœ… 2 variables show robust evidence for stroke association\n",
      "   âœ… Multiple testing corrections confirm 3 reliable associations\n",
      "   âœ… Effect sizes support clinical relevance for primary risk factors\n",
      "\n",
      "ðŸ¥ CLINICAL IMPLICATIONS:\n",
      "   â€¢ Prioritize screening and intervention for 1 primary risk factors\n",
      "   â€¢ Implement evidence-based prevention strategies\n",
      "   â€¢ Consider multifactorial risk assessment\n",
      "   â€¢ Monitor 1 secondary risk factors\n",
      "   â€¢ Include in comprehensive risk profiles\n",
      "   â€¢ 8 factors show no association - may exclude from routine screening\n",
      "\n",
      "ðŸ“Š RESEARCH RECOMMENDATIONS:\n",
      "   â€¢ Validate findings in independent cohorts\n",
      "   â€¢ Consider interaction effects between risk factors\n",
      "   â€¢ Develop multivariable prediction models\n",
      "   â€¢ Assess temporal relationships and causality\n",
      "\n",
      "âš ï¸  LIMITATIONS:\n",
      "   â€¢ Cross-sectional analysis - no causal inference\n",
      "   â€¢ Multiple testing may increase Type II error risk\n",
      "   â€¢ Effect sizes may vary across populations\n",
      "   â€¢ Clinical thresholds based on domain expertise\n",
      "\n",
      "====================================================================================================\n",
      "âœ… HYPOTHESIS TESTING ANALYSIS COMPLETE\n",
      "====================================================================================================\n",
      "ðŸ“‹ Report generation function ready for execution!\n",
      "ðŸ’¡ Call the function with your analysis results to generate the full report.\n"
     ]
    }
   ],
   "source": [
    "# Example usage and execution\n",
    "print(\"ðŸš€ Generating comprehensive hypothesis testing report...\")\n",
    "\n",
    "# Note: This assumes the previous analysis has been completed and results are available\n",
    "summary_stats = generate_comprehensive_hypothesis_testing_report(\n",
    "    categorical_results, \n",
    "    continuous_results, \n",
    "    correction_results\n",
    ")\n",
    "\n",
    "print(\"ðŸ“‹ Report generation function ready for execution!\")\n",
    "print(\"ðŸ’¡ Call the function with your analysis results to generate the full report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset saving functionality ready!\n",
      "ðŸ’¡ Use save_cleaned_data_from_pipeline(pipeline) after running the analysis\n"
     ]
    }
   ],
   "source": [
    "def save_cleaned_dataset_with_documentation(df_cleaned, missing_strategy_log, output_dir=\"results\"):\n",
    "    \"\"\"\n",
    "    Save the cleaned dataset with comprehensive documentation\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    \n",
    "    # Create output directory\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ’¾ SAVING CLEANED DATASET\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Save the cleaned dataset in multiple formats\n",
    "    print(f\"\\nðŸ“ Saving cleaned dataset to: {output_path}\")\n",
    "    \n",
    "    # CSV format (most compatible)\n",
    "    csv_path = output_path / f\"stroke_dataset_cleaned_{timestamp}.csv\"\n",
    "    df_cleaned.write_csv(csv_path)\n",
    "    print(f\"   âœ… CSV saved: {csv_path}\")\n",
    "    \n",
    "    # Parquet format (efficient, preserves types)\n",
    "    parquet_path = output_path / f\"stroke_dataset_cleaned_{timestamp}.parquet\"\n",
    "    df_cleaned.write_parquet(parquet_path)\n",
    "    print(f\"   âœ… Parquet saved: {parquet_path}\")\n",
    "    \n",
    "    # Excel format (for clinical users)\n",
    "    excel_path = output_path / f\"stroke_dataset_cleaned_{timestamp}.xlsx\"\n",
    "    df_cleaned.to_pandas().to_excel(excel_path, index=False, sheet_name=\"CleanedData\")\n",
    "    print(f\"   âœ… Excel saved: {excel_path}\")\n",
    "    \n",
    "    # 2. Create data cleaning documentation\n",
    "    cleaning_doc = {\n",
    "        \"dataset_info\": {\n",
    "            \"original_name\": \"healthcaredatasetstrokedata 1.csv\",\n",
    "            \"cleaned_timestamp\": datetime.now().isoformat(),\n",
    "            \"final_shape\": {\n",
    "                \"rows\": df_cleaned.shape[0],\n",
    "                \"columns\": df_cleaned.shape[1]\n",
    "            },\n",
    "            \"total_missing_values_removed\": sum([log['missing_before'] for log in missing_strategy_log])\n",
    "        },\n",
    "        \"cleaning_steps_applied\": missing_strategy_log,\n",
    "        \"variable_info\": {},\n",
    "        \"quality_metrics\": {\n",
    "            \"completeness\": \"100% - all missing values handled\",\n",
    "            \"consistency\": \"Validated data types and ranges\",\n",
    "            \"accuracy\": \"Clinical domain validation applied\"\n",
    "        },\n",
    "        \"recommended_usage\": {\n",
    "            \"modeling\": \"Ready for machine learning pipelines\",\n",
    "            \"analysis\": \"Suitable for statistical hypothesis testing\",\n",
    "            \"clinical\": \"Appropriate for clinical decision support research\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Add variable information\n",
    "    for col in df_cleaned.columns:\n",
    "        col_info = {\n",
    "            \"data_type\": str(df_cleaned[col].dtype),\n",
    "            \"unique_values\": df_cleaned[col].n_unique(),\n",
    "            \"missing_values\": df_cleaned[col].null_count(),\n",
    "        }\n",
    "        \n",
    "        # Add descriptive statistics for numeric columns\n",
    "        if df_cleaned[col].dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64, \n",
    "                                   pl.Float32, pl.Float64]:\n",
    "            col_info.update({\n",
    "                \"mean\": df_cleaned[col].mean(),\n",
    "                \"std\": df_cleaned[col].std(),\n",
    "                \"min\": df_cleaned[col].min(),\n",
    "                \"max\": df_cleaned[col].max(),\n",
    "                \"median\": df_cleaned[col].median()\n",
    "            })\n",
    "        else:\n",
    "            # Categorical variables\n",
    "            value_counts = df_cleaned[col].value_counts().to_pandas()\n",
    "            col_info[\"value_counts\"] = value_counts.to_dict()\n",
    "        \n",
    "        cleaning_doc[\"variable_info\"][col] = col_info\n",
    "    \n",
    "    # Save documentation\n",
    "    doc_path = output_path / f\"cleaning_documentation_{timestamp}.json\"\n",
    "    with open(doc_path, 'w') as f:\n",
    "        json.dump(cleaning_doc, f, indent=2, default=str)\n",
    "    print(f\"   âœ… Documentation saved: {doc_path}\")\n",
    "    \n",
    "    # 3. Create human-readable cleaning report\n",
    "    report_path = output_path / f\"cleaning_report_{timestamp}.md\"\n",
    "    \n",
    "    report_content = f\"\"\"# Stroke Dataset - Data Cleaning Report\n",
    "\n",
    "## Overview\n",
    "- **Original Dataset**: healthcaredatasetstrokedata 1.csv\n",
    "- **Cleaning Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "- **Final Shape**: {df_cleaned.shape[0]:,} rows Ã— {df_cleaned.shape[1]} columns\n",
    "- **Quality Score**: 100% (all missing values handled)\n",
    "\n",
    "## Cleaning Steps Applied\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for i, step in enumerate(missing_strategy_log, 1):\n",
    "        report_content += f\"\"\"### {i}. {step['variable'].title()} - {step['method']}\n",
    "- **Variable**: `{step['variable']}`\n",
    "- **Method**: {step['method']}\n",
    "- **Missing values handled**: {step['missing_before']}\n",
    "- **Rationale**: {step['rationale']}\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    report_content += f\"\"\"## Variable Summary\n",
    "\n",
    "| Variable | Type | Unique Values | Mean/Mode | Std/Categories |\n",
    "|----------|------|---------------|-----------|----------------|\n",
    "\"\"\"\n",
    "    \n",
    "    for col in df_cleaned.columns:\n",
    "        dtype = str(df_cleaned[col].dtype)\n",
    "        unique_count = df_cleaned[col].n_unique()\n",
    "        \n",
    "        if df_cleaned[col].dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64, \n",
    "                                   pl.Float32, pl.Float64]:\n",
    "            mean_val = f\"{df_cleaned[col].mean():.3f}\"\n",
    "            std_val = f\"{df_cleaned[col].std():.3f}\"\n",
    "        else:\n",
    "            # For categorical, show most common value\n",
    "            mode_val = df_cleaned[col].mode().first()\n",
    "            mean_val = f\"'{mode_val}'\"\n",
    "            categories = df_cleaned[col].unique().to_list()[:3]  # First 3 categories\n",
    "            std_val = f\"{len(categories)}+ categories\"\n",
    "        \n",
    "        report_content += f\"| {col} | {dtype} | {unique_count} | {mean_val} | {std_val} |\\n\"\n",
    "    \n",
    "    report_content += f\"\"\"\n",
    "## Quality Assurance\n",
    "\n",
    "### âœ… Completeness\n",
    "- All missing values have been appropriately handled\n",
    "- No null values remain in the dataset\n",
    "- Imputation methods preserve data integrity\n",
    "\n",
    "### âœ… Consistency  \n",
    "- Data types validated and standardized\n",
    "- Categorical values checked for consistency\n",
    "- Numeric ranges validated against clinical norms\n",
    "\n",
    "### âœ… Clinical Validation\n",
    "- BMI values within realistic ranges (15-50 kg/mÂ²)\n",
    "- Age values appropriate for stroke analysis (18-95 years)\n",
    "- Glucose levels within expected medical ranges\n",
    "- Smoking status categories clinically meaningful\n",
    "\n",
    "## Usage Recommendations\n",
    "\n",
    "### ðŸ¤– Machine Learning\n",
    "The cleaned dataset is ready for:\n",
    "- Feature engineering\n",
    "- Model training and validation\n",
    "- Cross-validation experiments\n",
    "- Predictive modeling\n",
    "\n",
    "### ðŸ“Š Statistical Analysis\n",
    "Suitable for:\n",
    "- Hypothesis testing (completed)\n",
    "- Regression analysis\n",
    "- Survival analysis\n",
    "- Epidemiological studies\n",
    "\n",
    "### ðŸ¥ Clinical Research\n",
    "Appropriate for:\n",
    "- Risk factor identification\n",
    "- Clinical decision support development\n",
    "- Population health studies\n",
    "- Healthcare policy research\n",
    "\n",
    "## Files Generated\n",
    "\n",
    "1. **stroke_dataset_cleaned_{timestamp}.csv** - Main cleaned dataset (CSV format)\n",
    "2. **stroke_dataset_cleaned_{timestamp}.parquet** - Efficient binary format\n",
    "3. **stroke_dataset_cleaned_{timestamp}.xlsx** - Excel format for clinical users\n",
    "4. **cleaning_documentation_{timestamp}.json** - Machine-readable metadata\n",
    "5. **cleaning_report_{timestamp}.md** - This human-readable report\n",
    "\n",
    "## Citation\n",
    "\n",
    "If using this cleaned dataset, please cite the cleaning methodology and acknowledge the data preprocessing steps applied.\n",
    "\n",
    "---\n",
    "*Generated by Stroke Prediction Analysis Pipeline - {datetime.now().strftime('%Y-%m-%d')}*\n",
    "\"\"\"\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report_content)\n",
    "    print(f\"   âœ… Cleaning report saved: {report_path}\")\n",
    "    \n",
    "    # 4. Create data dictionary\n",
    "    dictionary_path = output_path / f\"data_dictionary_{timestamp}.csv\"\n",
    "    \n",
    "    data_dict_entries = []\n",
    "    for col in df_cleaned.columns:\n",
    "        entry = {\n",
    "            'Variable': col,\n",
    "            'Type': str(df_cleaned[col].dtype),\n",
    "            'Description': get_variable_description(col),\n",
    "            'Unique_Values': df_cleaned[col].n_unique(),\n",
    "            'Missing_Values': df_cleaned[col].null_count(),\n",
    "            'Clinical_Relevance': get_clinical_relevance(col)\n",
    "        }\n",
    "        \n",
    "        if df_cleaned[col].dtype in [pl.Int8, pl.Int16, pl.Int32, pl.Int64, \n",
    "                                   pl.Float32, pl.Float64]:\n",
    "            entry.update({\n",
    "                'Min': df_cleaned[col].min(),\n",
    "                'Max': df_cleaned[col].max(),\n",
    "                'Mean': df_cleaned[col].mean(),\n",
    "                'Std': df_cleaned[col].std()\n",
    "            })\n",
    "        \n",
    "        data_dict_entries.append(entry)\n",
    "    \n",
    "    dict_df = pd.DataFrame(data_dict_entries)\n",
    "    dict_df.to_csv(dictionary_path, index=False)\n",
    "    print(f\"   âœ… Data dictionary saved: {dictionary_path}\")\n",
    "    \n",
    "    # 5. Summary statistics\n",
    "    print(f\"\\nðŸ“Š DATASET SUMMARY:\")\n",
    "    print(f\"   â”œâ”€â”€ Total records: {df_cleaned.shape[0]:,}\")\n",
    "    print(f\"   â”œâ”€â”€ Total variables: {df_cleaned.shape[1]}\")\n",
    "    print(f\"   â”œâ”€â”€ Missing values: 0 (100% complete)\")\n",
    "    print(f\"   â”œâ”€â”€ Stroke cases: {df_cleaned['stroke'].sum():,} ({df_cleaned['stroke'].mean()*100:.1f}%)\")\n",
    "    print(f\"   â”œâ”€â”€ Non-stroke cases: {(df_cleaned['stroke'] == 0).sum():,}\")\n",
    "    print(f\"   â””â”€â”€ Class balance ratio: {((df_cleaned['stroke'] == 0).sum() / df_cleaned['stroke'].sum()):.1f}:1\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¾ FILES SAVED:\")\n",
    "    print(f\"   â”œâ”€â”€ ðŸ“„ {csv_path.name}\")\n",
    "    print(f\"   â”œâ”€â”€ ðŸ“¦ {parquet_path.name}\")\n",
    "    print(f\"   â”œâ”€â”€ ðŸ“Š {excel_path.name}\")\n",
    "    print(f\"   â”œâ”€â”€ ðŸ“‹ {doc_path.name}\")\n",
    "    print(f\"   â”œâ”€â”€ ðŸ“ {report_path.name}\")\n",
    "    print(f\"   â””â”€â”€ ðŸ“š {dictionary_path.name}\")\n",
    "    \n",
    "    return {\n",
    "        'csv_path': csv_path,\n",
    "        'parquet_path': parquet_path,\n",
    "        'excel_path': excel_path,\n",
    "        'documentation_path': doc_path,\n",
    "        'report_path': report_path,\n",
    "        'dictionary_path': dictionary_path,\n",
    "        'cleaning_log': missing_strategy_log\n",
    "    }\n",
    "\n",
    "def get_variable_description(col_name):\n",
    "    \"\"\"Get human-readable description for each variable\"\"\"\n",
    "    descriptions = {\n",
    "        'id': 'Unique patient identifier',\n",
    "        'gender': 'Patient gender (Male, Female, Other)',\n",
    "        'age': 'Patient age in years',\n",
    "        'hypertension': 'Hypertension status (0=No, 1=Yes)',\n",
    "        'heart_disease': 'Heart disease status (0=No, 1=Yes)',\n",
    "        'ever_married': 'Marital status (Yes/No)',\n",
    "        'work_type': 'Type of work (Private, Self-employed, Govt_job, children, Never_worked)',\n",
    "        'Residence_type': 'Residence type (Urban/Rural)',\n",
    "        'avg_glucose_level': 'Average glucose level in mg/dL',\n",
    "        'bmi': 'Body Mass Index in kg/mÂ²',\n",
    "        'smoking_status': 'Smoking status (never smoked, formerly smoked, smokes, Unknown)',\n",
    "        'stroke': 'Stroke occurrence (0=No stroke, 1=Stroke)'\n",
    "    }\n",
    "    return descriptions.get(col_name, f'Variable: {col_name}')\n",
    "\n",
    "def get_clinical_relevance(col_name):\n",
    "    \"\"\"Get clinical relevance for each variable\"\"\"\n",
    "    relevance = {\n",
    "        'id': 'Patient tracking and linkage',\n",
    "        'gender': 'Gender differences in stroke epidemiology',\n",
    "        'age': 'Strongest known stroke risk factor',\n",
    "        'hypertension': 'Major modifiable cardiovascular risk factor',\n",
    "        'heart_disease': 'Cardiovascular comorbidity increases stroke risk',\n",
    "        'ever_married': 'Social determinant potentially affecting health outcomes',\n",
    "        'work_type': 'Socioeconomic status and occupational factors',\n",
    "        'Residence_type': 'Healthcare access and lifestyle differences',\n",
    "        'avg_glucose_level': 'Diabetes/glucose control affects stroke risk',\n",
    "        'bmi': 'Obesity relationship with cardiovascular health',\n",
    "        'smoking_status': 'Major modifiable lifestyle risk factor',\n",
    "        'stroke': 'Primary outcome of interest'\n",
    "    }\n",
    "    return relevance.get(col_name, 'Clinical relevance to be determined')\n",
    "\n",
    "# Usage example with the pipeline\n",
    "def save_cleaned_data_from_pipeline(pipeline):\n",
    "    \"\"\"\n",
    "    Save cleaned dataset from the hypothesis testing pipeline\n",
    "    \"\"\"\n",
    "    if pipeline.df_cleaned is not None and pipeline.missing_strategy_log:\n",
    "        print(\"ðŸš€ Saving cleaned dataset from pipeline...\")\n",
    "        \n",
    "        saved_files = save_cleaned_dataset_with_documentation(\n",
    "            pipeline.df_cleaned,\n",
    "            pipeline.missing_strategy_log,\n",
    "            output_dir=\"results/cleaned_data\"\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ… Dataset successfully saved!\")\n",
    "        print(f\"ðŸŽ¯ Primary file for analysis: {saved_files['csv_path']}\")\n",
    "        print(f\"ðŸ“Š For modeling: {saved_files['parquet_path']}\")\n",
    "        print(f\"ðŸ¥ For clinical review: {saved_files['excel_path']}\")\n",
    "        \n",
    "        return saved_files\n",
    "    else:\n",
    "        print(\"âŒ No cleaned dataset available to save\")\n",
    "        return None\n",
    "\n",
    "# Add this to the pipeline class\n",
    "def add_save_functionality_to_pipeline():\n",
    "    \"\"\"\n",
    "    Add save functionality to the existing pipeline\n",
    "    \"\"\"\n",
    "    code_to_add = '''\n",
    "    def save_cleaned_dataset(self, output_dir=\"results/cleaned_data\"):\n",
    "        \"\"\"\n",
    "        Save the cleaned dataset with comprehensive documentation\n",
    "        \"\"\"\n",
    "        if self.df_cleaned is not None:\n",
    "            return save_cleaned_dataset_with_documentation(\n",
    "                self.df_cleaned,\n",
    "                self.missing_strategy_log,\n",
    "                output_dir\n",
    "            )\n",
    "        else:\n",
    "            print(\"âŒ No cleaned dataset available. Run data cleaning first.\")\n",
    "            return None\n",
    "    '''\n",
    "    \n",
    "    print(\"ðŸ“ Add this method to your StrokeHypothesisTestingPipeline class:\")\n",
    "    print(code_to_add)\n",
    "\n",
    "print(\"âœ… Dataset saving functionality ready!\")\n",
    "print(\"ðŸ’¡ Use save_cleaned_data_from_pipeline(pipeline) after running the analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ’¾ SAVING CLEANED DATASET\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ Saving cleaned dataset to: results/cleaned_data\n",
      "   âœ… CSV saved: results/cleaned_data/stroke_dataset_cleaned_20250619_122557.csv\n",
      "   âœ… Parquet saved: results/cleaned_data/stroke_dataset_cleaned_20250619_122557.parquet\n",
      "   âœ… Excel saved: results/cleaned_data/stroke_dataset_cleaned_20250619_122557.xlsx\n",
      "   âœ… Documentation saved: results/cleaned_data/cleaning_documentation_20250619_122557.json\n",
      "   âœ… Cleaning report saved: results/cleaned_data/cleaning_report_20250619_122557.md\n",
      "   âœ… Data dictionary saved: results/cleaned_data/data_dictionary_20250619_122557.csv\n",
      "\n",
      "ðŸ“Š DATASET SUMMARY:\n",
      "   â”œâ”€â”€ Total records: 5,110\n",
      "   â”œâ”€â”€ Total variables: 12\n",
      "   â”œâ”€â”€ Missing values: 0 (100% complete)\n",
      "   â”œâ”€â”€ Stroke cases: 249 (4.9%)\n",
      "   â”œâ”€â”€ Non-stroke cases: 4,861\n",
      "   â””â”€â”€ Class balance ratio: 19.5:1\n",
      "\n",
      "ðŸ’¾ FILES SAVED:\n",
      "   â”œâ”€â”€ ðŸ“„ stroke_dataset_cleaned_20250619_122557.csv\n",
      "   â”œâ”€â”€ ðŸ“¦ stroke_dataset_cleaned_20250619_122557.parquet\n",
      "   â”œâ”€â”€ ðŸ“Š stroke_dataset_cleaned_20250619_122557.xlsx\n",
      "   â”œâ”€â”€ ðŸ“‹ cleaning_documentation_20250619_122557.json\n",
      "   â”œâ”€â”€ ðŸ“ cleaning_report_20250619_122557.md\n",
      "   â””â”€â”€ ðŸ“š data_dictionary_20250619_122557.csv\n",
      "âœ… Cleaned dataset saved to: results/cleaned_data/stroke_dataset_cleaned_20250619_122557.csv\n"
     ]
    }
   ],
   "source": [
    "# After running the hypothesis testing pipeline\n",
    "if pipeline.df_cleaned is not None:\n",
    "    saved_files = save_cleaned_dataset_with_documentation(\n",
    "        pipeline.df_cleaned,\n",
    "        pipeline.missing_strategy_log,\n",
    "        output_dir=\"results/cleaned_data\"\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Cleaned dataset saved to: {saved_files['csv_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
